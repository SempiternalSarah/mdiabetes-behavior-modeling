{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "214\n",
      "0\t train loss: 0.1657 train acc: 37.530% test acc: 38.892%\n",
      "5\t train loss: 0.1522 train acc: 51.084% test acc: 50.796%\n",
      "10\t train loss: 0.1492 train acc: 49.944% test acc: 49.558%\n",
      "15\t train loss: 0.1462 train acc: 51.662% test acc: 51.149%\n",
      "20\t train loss: 0.1443 train acc: 51.598% test acc: 51.149%\n",
      "25\t train loss: 0.1436 train acc: 51.678% test acc: 51.149%\n",
      "30\t train loss: 0.1427 train acc: 51.614% test acc: 50.972%\n",
      "35\t train loss: 0.1419 train acc: 51.871% test acc: 50.796%\n",
      "40\t train loss: 0.1412 train acc: 51.903% test acc: 50.737%\n",
      "45\t train loss: 0.1406 train acc: 51.919% test acc: 50.560%\n",
      "50\t train loss: 0.1401 train acc: 51.871% test acc: 50.678%\n",
      "55\t train loss: 0.1396 train acc: 51.871% test acc: 50.501%\n",
      "60\t train loss: 0.1391 train acc: 51.951% test acc: 50.501%\n",
      "65\t train loss: 0.1386 train acc: 51.967% test acc: 50.383%\n",
      "70\t train loss: 0.1382 train acc: 51.903% test acc: 50.383%\n",
      "75\t train loss: 0.1378 train acc: 51.951% test acc: 50.324%\n",
      "80\t train loss: 0.1374 train acc: 52.080% test acc: 50.265%\n",
      "85\t train loss: 0.1370 train acc: 52.947% test acc: 50.088%\n",
      "90\t train loss: 0.1366 train acc: 53.091% test acc: 49.971%\n",
      "95\t train loss: 0.1363 train acc: 53.509% test acc: 49.912%\n",
      "100\t train loss: 0.1360 train acc: 53.300% test acc: 50.442%\n",
      "105\t train loss: 0.1356 train acc: 53.589% test acc: 50.265%\n",
      "110\t train loss: 0.1353 train acc: 53.589% test acc: 49.912%\n",
      "115\t train loss: 0.1350 train acc: 53.686% test acc: 50.029%\n",
      "120\t train loss: 0.1352 train acc: 54.071% test acc: 48.733%\n",
      "125\t train loss: 0.1348 train acc: 54.280% test acc: 48.321%\n",
      "130\t train loss: 0.1345 train acc: 54.392% test acc: 48.262%\n",
      "135\t train loss: 0.1341 train acc: 55.500% test acc: 45.905%\n",
      "140\t train loss: 0.1339 train acc: 54.922% test acc: 46.258%\n",
      "145\t train loss: 0.1340 train acc: 54.489% test acc: 47.378%\n",
      "150\t train loss: 0.1336 train acc: 54.745% test acc: 46.847%\n",
      "155\t train loss: 0.1332 train acc: 54.922% test acc: 45.963%\n",
      "160\t train loss: 0.1331 train acc: 55.452% test acc: 46.258%\n",
      "165\t train loss: 0.1330 train acc: 55.870% test acc: 45.787%\n",
      "170\t train loss: 0.1329 train acc: 55.227% test acc: 46.081%\n",
      "175\t train loss: 0.1326 train acc: 55.998% test acc: 45.846%\n",
      "180\t train loss: 0.1324 train acc: 56.239% test acc: 45.905%\n",
      "185\t train loss: 0.1338 train acc: 54.778% test acc: 46.199%\n",
      "190\t train loss: 0.1329 train acc: 55.195% test acc: 46.081%\n",
      "195\t train loss: 0.1324 train acc: 55.629% test acc: 46.140%\n",
      "200\t train loss: 0.1320 train acc: 55.725% test acc: 45.963%\n",
      "205\t train loss: 0.1319 train acc: 56.223% test acc: 45.728%\n",
      "210\t train loss: 0.1318 train acc: 56.239% test acc: 45.492%\n",
      "215\t train loss: 0.1317 train acc: 56.207% test acc: 45.433%\n",
      "220\t train loss: 0.1314 train acc: 56.191% test acc: 45.021%\n",
      "225\t train loss: 0.1314 train acc: 56.785% test acc: 44.962%\n",
      "230\t train loss: 0.1313 train acc: 56.496% test acc: 44.785%\n",
      "235\t train loss: 0.1312 train acc: 56.608% test acc: 44.785%\n",
      "240\t train loss: 0.1310 train acc: 56.897% test acc: 44.608%\n",
      "245\t train loss: 0.1309 train acc: 56.528% test acc: 44.962%\n",
      "250\t train loss: 0.1314 train acc: 56.576% test acc: 44.549%\n",
      "255\t train loss: 0.1315 train acc: 56.801% test acc: 44.196%\n",
      "260\t train loss: 0.1310 train acc: 56.721% test acc: 44.549%\n",
      "265\t train loss: 0.1307 train acc: 56.737% test acc: 44.667%\n",
      "270\t train loss: 0.1306 train acc: 57.042% test acc: 44.372%\n",
      "275\t train loss: 0.1306 train acc: 56.721% test acc: 44.962%\n",
      "280\t train loss: 0.1303 train acc: 57.154% test acc: 44.255%\n",
      "285\t train loss: 0.1305 train acc: 57.026% test acc: 43.901%\n",
      "290\t train loss: 0.1302 train acc: 57.138% test acc: 44.549%\n",
      "295\t train loss: 0.1303 train acc: 56.881% test acc: 44.903%\n",
      "300\t train loss: 0.1301 train acc: 57.106% test acc: 44.078%\n",
      "305\t train loss: 0.1300 train acc: 57.074% test acc: 44.255%\n",
      "310\t train loss: 0.1299 train acc: 57.090% test acc: 44.078%\n",
      "315\t train loss: 0.1298 train acc: 57.154% test acc: 43.960%\n",
      "320\t train loss: 0.1297 train acc: 57.283% test acc: 43.960%\n",
      "325\t train loss: 0.1297 train acc: 57.170% test acc: 44.608%\n",
      "330\t train loss: 0.1299 train acc: 57.395% test acc: 43.960%\n",
      "335\t train loss: 0.1303 train acc: 56.881% test acc: 43.665%\n",
      "340\t train loss: 0.1297 train acc: 57.443% test acc: 43.606%\n",
      "345\t train loss: 0.1296 train acc: 57.459% test acc: 43.606%\n",
      "350\t train loss: 0.1294 train acc: 57.315% test acc: 43.606%\n",
      "355\t train loss: 0.1295 train acc: 57.235% test acc: 44.313%\n",
      "360\t train loss: 0.1293 train acc: 57.235% test acc: 43.665%\n",
      "365\t train loss: 0.1294 train acc: 57.331% test acc: 43.253%\n",
      "370\t train loss: 0.1296 train acc: 57.267% test acc: 44.137%\n",
      "375\t train loss: 0.1293 train acc: 57.186% test acc: 44.196%\n",
      "380\t train loss: 0.1292 train acc: 57.283% test acc: 43.371%\n",
      "385\t train loss: 0.1296 train acc: 57.251% test acc: 43.135%\n",
      "390\t train loss: 0.1294 train acc: 57.443% test acc: 43.194%\n",
      "395\t train loss: 0.1291 train acc: 57.459% test acc: 43.135%\n",
      "400\t train loss: 0.1289 train acc: 57.251% test acc: 43.253%\n",
      "405\t train loss: 0.1288 train acc: 57.524% test acc: 43.312%\n",
      "410\t train loss: 0.1287 train acc: 57.524% test acc: 43.665%\n",
      "415\t train loss: 0.1287 train acc: 57.443% test acc: 43.783%\n",
      "420\t train loss: 0.1286 train acc: 57.572% test acc: 43.489%\n",
      "425\t train loss: 0.1287 train acc: 57.106% test acc: 43.194%\n",
      "430\t train loss: 0.1285 train acc: 57.604% test acc: 43.783%\n",
      "435\t train loss: 0.1285 train acc: 57.620% test acc: 43.842%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_52628\\1220236294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\experiment.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"_kw\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;31m# results = self.evaluate()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeroStateFeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             \u001b[0mlh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;31m# update our predictions as features when appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\experiment.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self, opt)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;31m# no special trick here - the dimensions work to be non batched in LSTM (as desired)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[1;31m# and batched by week for non LSTM models (also as desired)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\models\\BasicNN.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mout_q1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_q1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mout_q2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_q2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout_q1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_q2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model, learning_rate = \"AdaptableLSTM\", .025\n",
    "model, learning_rate = \"BasicNN\", .0054\n",
    "# model, learning_rate = \"LogisticRegressor\", .003\n",
    "epochs = 1000\n",
    "seed = 1\n",
    "include_state = True\n",
    "estate = True\n",
    "fullq = True\n",
    "respond_perc = .50\n",
    "fullseq = True\n",
    "insertpreds = True\n",
    "noise = 0\n",
    "smooth = .1\n",
    "stateZeroEpochs = 0\n",
    "\n",
    "    \n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "e = Experiment(\n",
    "    stateZeroEpochs = stateZeroEpochs,\n",
    "    numValFolds = 5,\n",
    "    epochsToUpdateLabelMods = 10,\n",
    "    data_kw={\"minw\": 2,\n",
    "            \"maxw\": 29,\n",
    "            \"include_state\": include_state,\n",
    "            \"include_pid\": False,\n",
    "            \"expanded_states\": estate,\n",
    "            \"top_respond_perc\": respond_perc,\n",
    "             \"full_questionnaire\": fullq,\n",
    "             \"full_sequence\": fullseq,\n",
    "             \"insert_predictions\": insertpreds,\n",
    "             \"one_hot_response_features\": False,\n",
    "             \"response_feature_noise\": noise\n",
    "            },\n",
    "    model=model,\n",
    "    model_kw={\n",
    "        \"lossfn\": \"MSELoss\",\n",
    "        # \"lossfn\": \"NDCG\",\n",
    "        # \"lossfn\": \"CrossEntropyLoss\",\n",
    "        \"hidden_size\": 15,\n",
    "        \"lr_step_mult\": .9, \n",
    "        \"lr_step_epochs\": 100,\n",
    "        \"opt_kw\": {\n",
    "            \"lr\": learning_rate,\n",
    "        },\n",
    "        \"labelSmoothPerc\": smooth,\n",
    "        \"gaussianNoiseStd\": noise\n",
    "        \n",
    "    },\n",
    "    train_kw={\n",
    "        \"epochs\": epochs,\n",
    "        \"n_subj\": 500,\n",
    "        \"rec_every\": 5,\n",
    "    })\n",
    "\n",
    "\n",
    "print(len(e.bd.test))\n",
    "print(len(e.bd.train))\n",
    "\n",
    "report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de6743-690e-463b-b5b0-212eb0da9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (np.mean(report['train_metrics'], axis=0))\n",
    "labels = report[\"metric_labels\"]\n",
    "print(report['train_metrics'][-1, labels.index(\"Acc\")])\n",
    "print(report['test_metrics'][-1, labels.index(\"Acc\")])\n",
    "\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "plt.title(\"Train/Test Performance Over Training\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.savefig(\"simpleNotebookAccPlot.png\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5928e0-08ac-4055-9bc6-89fe1fea6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e.bd.features.shape, e.bd.featureList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41511c-c598-4167-9570-c6b6a75c927a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
