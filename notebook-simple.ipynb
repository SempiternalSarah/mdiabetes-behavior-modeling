{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "214\n",
      "0\t train loss: 0.2318 train acc: 51.598% test acc: 51.149%\n",
      "5\t train loss: 0.2318 train acc: 51.598% test acc: 51.149%\n",
      "10\t train loss: 0.2205 train acc: 51.598% test acc: 51.149%\n",
      "15\t train loss: 0.2177 train acc: 51.598% test acc: 51.149%\n",
      "20\t train loss: 0.2163 train acc: 51.598% test acc: 51.149%\n",
      "25\t train loss: 0.2159 train acc: 51.598% test acc: 51.149%\n",
      "30\t train loss: 0.2137 train acc: 51.598% test acc: 51.149%\n",
      "35\t train loss: 0.2126 train acc: 51.598% test acc: 51.149%\n",
      "40\t train loss: 0.2103 train acc: 51.598% test acc: 51.149%\n",
      "45\t train loss: 0.2087 train acc: 52.369% test acc: 51.915%\n",
      "50\t train loss: 0.2044 train acc: 53.525% test acc: 52.799%\n",
      "55\t train loss: 0.2007 train acc: 54.248% test acc: 53.329%\n",
      "60\t train loss: 0.1981 train acc: 54.778% test acc: 53.742%\n",
      "65\t train loss: 0.1974 train acc: 55.773% test acc: 55.038%\n",
      "70\t train loss: 0.1947 train acc: 56.207% test acc: 55.451%\n",
      "75\t train loss: 0.1943 train acc: 56.528% test acc: 55.745%\n",
      "80\t train loss: 0.1901 train acc: 56.913% test acc: 55.392%\n",
      "85\t train loss: 0.1907 train acc: 57.090% test acc: 55.628%\n",
      "90\t train loss: 0.1879 train acc: 58.086% test acc: 55.922%\n",
      "95\t train loss: 0.1882 train acc: 57.989% test acc: 56.570%\n",
      "100\t train loss: 0.1865 train acc: 58.664% test acc: 56.217%\n",
      "105\t train loss: 0.1844 train acc: 58.857% test acc: 56.806%\n",
      "110\t train loss: 0.1844 train acc: 58.953% test acc: 57.219%\n",
      "115\t train loss: 0.1834 train acc: 59.097% test acc: 57.278%\n",
      "120\t train loss: 0.1842 train acc: 59.242% test acc: 57.395%\n",
      "125\t train loss: 0.1820 train acc: 59.708% test acc: 57.160%\n",
      "130\t train loss: 0.1815 train acc: 59.836% test acc: 57.042%\n",
      "135\t train loss: 0.1800 train acc: 60.045% test acc: 56.629%\n",
      "140\t train loss: 0.1798 train acc: 60.543% test acc: 56.924%\n",
      "145\t train loss: 0.1786 train acc: 61.233% test acc: 56.747%\n",
      "150\t train loss: 0.1772 train acc: 61.249% test acc: 56.217%\n",
      "155\t train loss: 0.1771 train acc: 60.944% test acc: 55.922%\n",
      "160\t train loss: 0.1766 train acc: 61.506% test acc: 56.394%\n",
      "165\t train loss: 0.1749 train acc: 61.924% test acc: 56.511%\n",
      "170\t train loss: 0.1762 train acc: 61.779% test acc: 56.629%\n",
      "175\t train loss: 0.1750 train acc: 62.277% test acc: 56.511%\n",
      "180\t train loss: 0.1734 train acc: 63.032% test acc: 56.040%\n",
      "185\t train loss: 0.1744 train acc: 62.871% test acc: 56.511%\n",
      "190\t train loss: 0.1733 train acc: 62.229% test acc: 55.981%\n",
      "195\t train loss: 0.1717 train acc: 62.727% test acc: 56.217%\n",
      "200\t train loss: 0.1724 train acc: 63.225% test acc: 56.099%\n",
      "205\t train loss: 0.1704 train acc: 63.466% test acc: 55.981%\n",
      "210\t train loss: 0.1697 train acc: 63.594% test acc: 55.745%\n",
      "215\t train loss: 0.1709 train acc: 64.012% test acc: 55.804%\n",
      "220\t train loss: 0.1695 train acc: 64.574% test acc: 55.392%\n",
      "225\t train loss: 0.1683 train acc: 64.863% test acc: 54.154%\n",
      "230\t train loss: 0.1719 train acc: 64.429% test acc: 54.979%\n",
      "235\t train loss: 0.1704 train acc: 63.433% test acc: 54.862%\n",
      "240\t train loss: 0.1691 train acc: 65.120% test acc: 54.803%\n",
      "245\t train loss: 0.1682 train acc: 64.574% test acc: 55.687%\n",
      "250\t train loss: 0.1671 train acc: 65.569% test acc: 55.274%\n",
      "255\t train loss: 0.1657 train acc: 65.617% test acc: 55.863%\n",
      "260\t train loss: 0.1644 train acc: 65.344% test acc: 55.687%\n",
      "265\t train loss: 0.1652 train acc: 65.890% test acc: 55.392%\n",
      "270\t train loss: 0.1629 train acc: 66.629% test acc: 54.567%\n",
      "275\t train loss: 0.1629 train acc: 66.356% test acc: 54.803%\n",
      "280\t train loss: 0.1615 train acc: 66.999% test acc: 55.156%\n",
      "285\t train loss: 0.1612 train acc: 67.015% test acc: 55.215%\n",
      "290\t train loss: 0.1612 train acc: 67.641% test acc: 53.978%\n",
      "295\t train loss: 0.1607 train acc: 67.191% test acc: 55.156%\n",
      "300\t train loss: 0.1605 train acc: 67.063% test acc: 55.038%\n",
      "305\t train loss: 0.1586 train acc: 68.235% test acc: 54.272%\n",
      "310\t train loss: 0.1577 train acc: 68.283% test acc: 53.801%\n",
      "315\t train loss: 0.1565 train acc: 68.717% test acc: 54.331%\n",
      "320\t train loss: 0.1560 train acc: 68.717% test acc: 54.508%\n",
      "325\t train loss: 0.1565 train acc: 69.311% test acc: 54.390%\n",
      "330\t train loss: 0.1546 train acc: 69.520% test acc: 53.683%\n",
      "335\t train loss: 0.1541 train acc: 69.696% test acc: 54.095%\n",
      "340\t train loss: 0.1532 train acc: 69.889% test acc: 53.801%\n",
      "345\t train loss: 0.1546 train acc: 68.428% test acc: 54.390%\n",
      "350\t train loss: 0.1542 train acc: 68.460% test acc: 54.979%\n",
      "355\t train loss: 0.1523 train acc: 69.231% test acc: 54.508%\n",
      "360\t train loss: 0.1521 train acc: 69.407% test acc: 54.979%\n",
      "365\t train loss: 0.1505 train acc: 70.098% test acc: 54.567%\n",
      "370\t train loss: 0.1493 train acc: 70.114% test acc: 53.919%\n",
      "375\t train loss: 0.1484 train acc: 70.805% test acc: 54.331%\n",
      "380\t train loss: 0.1492 train acc: 71.174% test acc: 53.742%\n",
      "385\t train loss: 0.1496 train acc: 71.704% test acc: 52.622%\n",
      "390\t train loss: 0.1496 train acc: 71.527% test acc: 52.563%\n",
      "395\t train loss: 0.1476 train acc: 71.479% test acc: 53.094%\n",
      "400\t train loss: 0.1466 train acc: 71.784% test acc: 53.565%\n",
      "405\t train loss: 0.1461 train acc: 71.913% test acc: 53.329%\n",
      "410\t train loss: 0.1451 train acc: 72.250% test acc: 53.447%\n",
      "415\t train loss: 0.1445 train acc: 72.507% test acc: 53.683%\n",
      "420\t train loss: 0.1442 train acc: 71.832% test acc: 54.154%\n",
      "425\t train loss: 0.1450 train acc: 71.977% test acc: 54.331%\n",
      "430\t train loss: 0.1441 train acc: 72.587% test acc: 53.094%\n",
      "435\t train loss: 0.1426 train acc: 72.860% test acc: 53.388%\n",
      "440\t train loss: 0.1424 train acc: 72.587% test acc: 54.037%\n",
      "445\t train loss: 0.1419 train acc: 72.989% test acc: 53.978%\n",
      "450\t train loss: 0.1425 train acc: 72.378% test acc: 54.272%\n",
      "455\t train loss: 0.1433 train acc: 73.133% test acc: 53.742%\n",
      "460\t train loss: 0.1434 train acc: 72.330% test acc: 53.035%\n",
      "465\t train loss: 0.1425 train acc: 72.186% test acc: 52.504%\n",
      "470\t train loss: 0.1452 train acc: 73.229% test acc: 53.978%\n",
      "475\t train loss: 0.1397 train acc: 73.101% test acc: 54.685%\n",
      "480\t train loss: 0.1395 train acc: 73.438% test acc: 54.449%\n",
      "485\t train loss: 0.1383 train acc: 73.470% test acc: 53.860%\n",
      "490\t train loss: 0.1387 train acc: 73.775% test acc: 53.742%\n",
      "495\t train loss: 0.1376 train acc: 73.920% test acc: 54.154%\n",
      "500\t train loss: 0.1372 train acc: 73.599% test acc: 54.095%\n",
      "505\t train loss: 0.1375 train acc: 73.663% test acc: 54.567%\n",
      "510\t train loss: 0.1373 train acc: 74.097% test acc: 54.272%\n",
      "515\t train loss: 0.1345 train acc: 74.065% test acc: 54.154%\n",
      "520\t train loss: 0.1362 train acc: 74.273% test acc: 54.037%\n",
      "525\t train loss: 0.1366 train acc: 74.530% test acc: 54.154%\n",
      "530\t train loss: 0.1349 train acc: 74.851% test acc: 53.683%\n",
      "535\t train loss: 0.1349 train acc: 73.904% test acc: 54.626%\n",
      "540\t train loss: 0.1349 train acc: 74.723% test acc: 53.919%\n",
      "545\t train loss: 0.1362 train acc: 74.723% test acc: 53.742%\n",
      "550\t train loss: 0.1358 train acc: 74.980% test acc: 53.506%\n",
      "555\t train loss: 0.1334 train acc: 75.430% test acc: 54.095%\n",
      "560\t train loss: 0.1336 train acc: 75.108% test acc: 54.331%\n",
      "565\t train loss: 0.1323 train acc: 75.654% test acc: 53.860%\n",
      "570\t train loss: 0.1316 train acc: 75.076% test acc: 54.390%\n",
      "575\t train loss: 0.1321 train acc: 75.687% test acc: 54.154%\n",
      "580\t train loss: 0.1314 train acc: 75.751% test acc: 53.447%\n",
      "585\t train loss: 0.1334 train acc: 74.016% test acc: 54.862%\n",
      "590\t train loss: 0.1315 train acc: 75.542% test acc: 54.862%\n",
      "595\t train loss: 0.1320 train acc: 75.992% test acc: 53.978%\n",
      "600\t train loss: 0.1307 train acc: 75.703% test acc: 54.037%\n",
      "605\t train loss: 0.1309 train acc: 75.927% test acc: 53.860%\n",
      "610\t train loss: 0.1295 train acc: 76.056% test acc: 54.390%\n",
      "615\t train loss: 0.1289 train acc: 76.313% test acc: 54.272%\n",
      "620\t train loss: 0.1278 train acc: 76.265% test acc: 53.801%\n",
      "625\t train loss: 0.1287 train acc: 76.216% test acc: 53.919%\n",
      "630\t train loss: 0.1282 train acc: 76.281% test acc: 54.037%\n",
      "635\t train loss: 0.1276 train acc: 76.522% test acc: 53.860%\n",
      "640\t train loss: 0.1262 train acc: 76.859% test acc: 53.388%\n",
      "645\t train loss: 0.1270 train acc: 76.698% test acc: 53.742%\n",
      "650\t train loss: 0.1276 train acc: 76.522% test acc: 53.978%\n",
      "655\t train loss: 0.1304 train acc: 76.730% test acc: 52.504%\n",
      "660\t train loss: 0.1283 train acc: 76.779% test acc: 52.563%\n",
      "665\t train loss: 0.1267 train acc: 76.939% test acc: 52.681%\n",
      "670\t train loss: 0.1269 train acc: 77.244% test acc: 53.094%\n",
      "675\t train loss: 0.1268 train acc: 77.308% test acc: 53.506%\n",
      "680\t train loss: 0.1258 train acc: 77.453% test acc: 53.683%\n",
      "685\t train loss: 0.1254 train acc: 77.148% test acc: 53.919%\n",
      "690\t train loss: 0.1257 train acc: 77.244% test acc: 54.095%\n",
      "695\t train loss: 0.1264 train acc: 77.244% test acc: 53.388%\n",
      "700\t train loss: 0.1249 train acc: 77.678% test acc: 53.270%\n",
      "705\t train loss: 0.1242 train acc: 77.806% test acc: 53.624%\n",
      "710\t train loss: 0.1244 train acc: 77.774% test acc: 53.388%\n",
      "715\t train loss: 0.1231 train acc: 77.774% test acc: 53.801%\n",
      "720\t train loss: 0.1238 train acc: 77.662% test acc: 53.506%\n",
      "725\t train loss: 0.1238 train acc: 78.015% test acc: 53.860%\n",
      "730\t train loss: 0.1232 train acc: 78.208% test acc: 52.681%\n",
      "735\t train loss: 0.1226 train acc: 78.192% test acc: 53.506%\n",
      "740\t train loss: 0.1231 train acc: 78.015% test acc: 53.683%\n",
      "745\t train loss: 0.1223 train acc: 78.240% test acc: 53.447%\n",
      "750\t train loss: 0.1234 train acc: 77.325% test acc: 54.213%\n",
      "755\t train loss: 0.1221 train acc: 78.224% test acc: 53.801%\n",
      "760\t train loss: 0.1225 train acc: 78.465% test acc: 53.035%\n",
      "765\t train loss: 0.1234 train acc: 78.497% test acc: 52.504%\n",
      "770\t train loss: 0.1218 train acc: 78.561% test acc: 53.212%\n",
      "775\t train loss: 0.1217 train acc: 78.465% test acc: 53.212%\n",
      "780\t train loss: 0.1215 train acc: 78.497% test acc: 54.095%\n",
      "785\t train loss: 0.1197 train acc: 78.738% test acc: 53.860%\n",
      "790\t train loss: 0.1207 train acc: 79.027% test acc: 53.565%\n",
      "795\t train loss: 0.1204 train acc: 78.818% test acc: 53.683%\n",
      "800\t train loss: 0.1204 train acc: 78.641% test acc: 53.801%\n",
      "805\t train loss: 0.1201 train acc: 78.947% test acc: 54.213%\n",
      "810\t train loss: 0.1197 train acc: 78.898% test acc: 53.447%\n",
      "815\t train loss: 0.1189 train acc: 79.027% test acc: 53.565%\n",
      "820\t train loss: 0.1210 train acc: 78.625% test acc: 53.919%\n",
      "825\t train loss: 0.1208 train acc: 79.155% test acc: 52.976%\n",
      "830\t train loss: 0.1199 train acc: 79.203% test acc: 52.858%\n",
      "835\t train loss: 0.1187 train acc: 79.316% test acc: 52.976%\n",
      "840\t train loss: 0.1180 train acc: 79.444% test acc: 53.153%\n",
      "845\t train loss: 0.1182 train acc: 79.380% test acc: 53.388%\n",
      "850\t train loss: 0.1182 train acc: 79.011% test acc: 53.801%\n",
      "855\t train loss: 0.1198 train acc: 79.252% test acc: 53.801%\n",
      "860\t train loss: 0.1181 train acc: 79.476% test acc: 53.683%\n",
      "865\t train loss: 0.1175 train acc: 79.493% test acc: 52.269%\n",
      "870\t train loss: 0.1176 train acc: 79.332% test acc: 53.153%\n",
      "875\t train loss: 0.1180 train acc: 79.075% test acc: 53.270%\n",
      "880\t train loss: 0.1180 train acc: 79.766% test acc: 52.976%\n",
      "885\t train loss: 0.1174 train acc: 79.589% test acc: 53.035%\n",
      "890\t train loss: 0.1171 train acc: 79.958% test acc: 52.622%\n",
      "895\t train loss: 0.1166 train acc: 79.894% test acc: 52.976%\n",
      "900\t train loss: 0.1164 train acc: 79.814% test acc: 53.094%\n",
      "905\t train loss: 0.1160 train acc: 79.814% test acc: 53.153%\n",
      "910\t train loss: 0.1157 train acc: 79.894% test acc: 52.976%\n",
      "915\t train loss: 0.1161 train acc: 80.231% test acc: 52.799%\n",
      "920\t train loss: 0.1170 train acc: 80.087% test acc: 52.445%\n",
      "925\t train loss: 0.1157 train acc: 80.263% test acc: 52.445%\n",
      "930\t train loss: 0.1156 train acc: 79.958% test acc: 52.799%\n",
      "935\t train loss: 0.1156 train acc: 80.151% test acc: 53.035%\n",
      "940\t train loss: 0.1150 train acc: 80.360% test acc: 52.740%\n",
      "945\t train loss: 0.1148 train acc: 80.552% test acc: 52.504%\n",
      "950\t train loss: 0.1151 train acc: 80.360% test acc: 52.563%\n",
      "955\t train loss: 0.1152 train acc: 80.328% test acc: 52.740%\n",
      "960\t train loss: 0.1161 train acc: 79.733% test acc: 53.035%\n",
      "965\t train loss: 0.1140 train acc: 80.312% test acc: 52.858%\n",
      "970\t train loss: 0.1143 train acc: 80.585% test acc: 52.681%\n",
      "975\t train loss: 0.1151 train acc: 80.649% test acc: 52.445%\n",
      "980\t train loss: 0.1149 train acc: 80.601% test acc: 52.210%\n",
      "985\t train loss: 0.1136 train acc: 80.729% test acc: 52.681%\n",
      "990\t train loss: 0.1143 train acc: 80.777% test acc: 52.917%\n",
      "995\t train loss: 0.1146 train acc: 80.183% test acc: 52.681%\n",
      "999\t train loss: 0.1134 train acc: 81.018% test acc: 52.622%\n"
     ]
    }
   ],
   "source": [
    "model, learning_rate = \"AdaptableLSTM\", .025\n",
    "# model, learning_rate = \"BasicNN\", .0024\n",
    "# model, learning_rate = \"LogisticRegressor\", .003\n",
    "epochs = 1000\n",
    "seed = 1\n",
    "include_state = True\n",
    "estate = True\n",
    "fullq = True\n",
    "respond_perc = .50\n",
    "fullseq = False\n",
    "insertpreds = True\n",
    "noise = .1\n",
    "smooth = 0\n",
    "\n",
    "    \n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "e = Experiment(\n",
    "    numValFolds = 5,\n",
    "    epochsToUpdateLabelMods = 5,\n",
    "    data_kw={\"minw\": 2,\n",
    "            \"maxw\": 29,\n",
    "            \"include_state\": include_state,\n",
    "            \"include_pid\": False,\n",
    "            \"expanded_states\": estate,\n",
    "            \"top_respond_perc\": respond_perc,\n",
    "             \"full_questionnaire\": fullq,\n",
    "             \"full_sequence\": fullseq,\n",
    "             \"insert_predictions\": insertpreds,\n",
    "             \"one_hot_response_features\": True\n",
    "            },\n",
    "    model=model,\n",
    "    model_kw={\n",
    "        \"lossfn\": \"MSELoss\",\n",
    "        # \"lossfn\": \"NDCG\",\n",
    "        # \"lossfn\": \"CrossEntropyLoss\",\n",
    "        \"hidden_size\": 200,\n",
    "        \"lr_step_mult\": .9, \n",
    "        \"lr_step_epochs\": 100,\n",
    "        \"opt_kw\": {\n",
    "            \"lr\": learning_rate,\n",
    "        },\n",
    "        \"labelSmoothPerc\": smooth,\n",
    "        \"gaussianNoiseStd\": noise\n",
    "        \n",
    "    },\n",
    "    train_kw={\n",
    "        \"epochs\": epochs,\n",
    "        \"n_subj\": 500,\n",
    "        \"rec_every\": 5,\n",
    "    })\n",
    "\n",
    "\n",
    "print(len(e.bd.test))\n",
    "print(len(e.bd.train))\n",
    "\n",
    "report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71de6743-690e-463b-b5b0-212eb0da9165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.36698756e-01 8.90791992e-01 8.79866736e-01 8.38381156e-01\n",
      " 7.12001261e-01 7.12001261e-01 7.12001261e-01 4.65311713e-01\n",
      " 6.04538031e-01 8.80970195e-01 6.07252966e-01 6.38619485e-01\n",
      " 7.50077485e-01 4.65311713e-01 6.04538031e-01 8.80970195e-01\n",
      " 1.57300000e+03 1.44100000e+03 3.21300000e+03]\n",
      "0.8101814389228821\n",
      "0.5262227654457092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print (np.mean(report['train_metrics'], axis=0))\n",
    "labels = report[\"metric_labels\"]\n",
    "print(report['train_metrics'][-1, labels.index(\"Acc\")])\n",
    "print(report['test_metrics'][-1, labels.index(\"Acc\")])\n",
    "\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "plt.title(\"Train/Test Performance Over Training\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.savefig(\"simpleNotebookAccPlot.png\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5928e0-08ac-4055-9bc6-89fe1fea6d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
