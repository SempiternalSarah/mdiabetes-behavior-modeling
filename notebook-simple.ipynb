{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 537\n",
      "paction_sids\n",
      "pmsg_ids\n",
      "qids\n",
      "response\n",
      "(6456, 928) (6456, 8) 928\n",
      "54\n",
      "214\n",
      "0\t train loss: 0.1635 train acc: 45.717% test acc: 43.603%\n",
      "5\t train loss: 0.1488 train acc: 49.680% test acc: 48.250%\n",
      "10\t train loss: 0.1435 train acc: 51.854% test acc: 50.488%\n",
      "15\t train loss: 0.1437 train acc: 52.189% test acc: 50.258%\n",
      "20\t train loss: 0.1410 train acc: 52.045% test acc: 50.660%\n",
      "25\t train loss: 0.1389 train acc: 52.780% test acc: 50.660%\n",
      "30\t train loss: 0.1369 train acc: 53.116% test acc: 51.061%\n",
      "35\t train loss: 0.1352 train acc: 53.388% test acc: 51.291%\n",
      "40\t train loss: 0.1337 train acc: 54.634% test acc: 50.832%\n",
      "45\t train loss: 0.1322 train acc: 55.513% test acc: 50.717%\n",
      "50\t train loss: 0.1306 train acc: 56.488% test acc: 50.373%\n",
      "55\t train loss: 0.1291 train acc: 57.143% test acc: 50.373%\n",
      "60\t train loss: 0.1276 train acc: 57.686% test acc: 50.258%\n",
      "65\t train loss: 0.1266 train acc: 58.357% test acc: 50.086%\n",
      "70\t train loss: 0.1249 train acc: 59.092% test acc: 50.545%\n",
      "75\t train loss: 0.1236 train acc: 59.588% test acc: 50.373%\n",
      "80\t train loss: 0.1222 train acc: 60.515% test acc: 49.627%\n",
      "85\t train loss: 0.1228 train acc: 60.211% test acc: 49.742%\n",
      "90\t train loss: 0.1198 train acc: 61.218% test acc: 48.537%\n",
      "95\t train loss: 0.1191 train acc: 61.889% test acc: 48.881%\n",
      "100\t train loss: 0.1177 train acc: 62.144% test acc: 49.168%\n",
      "105\t train loss: 0.1167 train acc: 62.480% test acc: 49.168%\n",
      "110\t train loss: 0.1157 train acc: 63.167% test acc: 48.594%\n",
      "115\t train loss: 0.1149 train acc: 63.822% test acc: 47.504%\n",
      "120\t train loss: 0.1147 train acc: 63.519% test acc: 47.619%\n",
      "125\t train loss: 0.1138 train acc: 64.222% test acc: 47.275%\n",
      "130\t train loss: 0.1125 train acc: 64.605% test acc: 47.332%\n",
      "135\t train loss: 0.1117 train acc: 65.388% test acc: 46.931%\n",
      "140\t train loss: 0.1108 train acc: 65.420% test acc: 46.931%\n",
      "145\t train loss: 0.1101 train acc: 65.676% test acc: 46.414%\n",
      "150\t train loss: 0.1089 train acc: 66.219% test acc: 46.414%\n",
      "155\t train loss: 0.1090 train acc: 66.363% test acc: 46.414%\n",
      "160\t train loss: 0.1077 train acc: 66.731% test acc: 45.783%\n",
      "165\t train loss: 0.1069 train acc: 67.178% test acc: 45.496%\n",
      "170\t train loss: 0.1075 train acc: 66.779% test acc: 45.841%\n",
      "175\t train loss: 0.1068 train acc: 67.082% test acc: 45.726%\n",
      "180\t train loss: 0.1053 train acc: 67.593% test acc: 45.668%\n",
      "185\t train loss: 0.1044 train acc: 67.785% test acc: 45.841%\n",
      "190\t train loss: 0.1037 train acc: 68.233% test acc: 45.382%\n",
      "195\t train loss: 0.1031 train acc: 68.696% test acc: 46.127%\n",
      "200\t train loss: 0.1042 train acc: 68.105% test acc: 44.980%\n",
      "205\t train loss: 0.1022 train acc: 69.159% test acc: 45.841%\n",
      "210\t train loss: 0.1013 train acc: 69.175% test acc: 45.439%\n",
      "215\t train loss: 0.1014 train acc: 69.399% test acc: 45.668%\n",
      "220\t train loss: 0.1006 train acc: 69.623% test acc: 44.923%\n",
      "225\t train loss: 0.1001 train acc: 69.767% test acc: 45.209%\n",
      "230\t train loss: 0.0999 train acc: 69.879% test acc: 45.267%\n",
      "235\t train loss: 0.0990 train acc: 70.198% test acc: 45.095%\n",
      "240\t train loss: 0.0994 train acc: 69.655% test acc: 44.693%\n",
      "245\t train loss: 0.0994 train acc: 69.591% test acc: 44.750%\n",
      "250\t train loss: 0.0980 train acc: 70.278% test acc: 44.808%\n",
      "255\t train loss: 0.0979 train acc: 70.805% test acc: 44.980%\n",
      "260\t train loss: 0.0974 train acc: 71.397% test acc: 44.406%\n",
      "265\t train loss: 0.0969 train acc: 71.780% test acc: 44.349%\n",
      "270\t train loss: 0.0963 train acc: 71.237% test acc: 45.037%\n",
      "275\t train loss: 0.0964 train acc: 71.445% test acc: 44.980%\n",
      "280\t train loss: 0.0959 train acc: 71.524% test acc: 44.980%\n",
      "285\t train loss: 0.0951 train acc: 72.020% test acc: 44.636%\n",
      "290\t train loss: 0.0952 train acc: 71.732% test acc: 44.291%\n",
      "295\t train loss: 0.0957 train acc: 71.221% test acc: 43.947%\n",
      "300\t train loss: 0.0941 train acc: 71.876% test acc: 44.062%\n",
      "305\t train loss: 0.0938 train acc: 72.275% test acc: 43.488%\n",
      "310\t train loss: 0.0934 train acc: 72.499% test acc: 43.144%\n",
      "315\t train loss: 0.0931 train acc: 72.611% test acc: 43.603%\n",
      "320\t train loss: 0.0927 train acc: 72.771% test acc: 43.316%\n",
      "325\t train loss: 0.0929 train acc: 72.979% test acc: 43.373%\n",
      "330\t train loss: 0.0921 train acc: 73.410% test acc: 42.915%\n",
      "335\t train loss: 0.0925 train acc: 72.675% test acc: 43.201%\n",
      "340\t train loss: 0.0915 train acc: 73.218% test acc: 43.316%\n",
      "345\t train loss: 0.0920 train acc: 73.154% test acc: 43.373%\n",
      "350\t train loss: 0.0910 train acc: 73.650% test acc: 43.087%\n",
      "355\t train loss: 0.0912 train acc: 73.554% test acc: 43.029%\n",
      "360\t train loss: 0.0908 train acc: 73.506% test acc: 43.259%\n",
      "365\t train loss: 0.0904 train acc: 73.426% test acc: 43.488%\n",
      "370\t train loss: 0.0902 train acc: 73.794% test acc: 43.488%\n",
      "375\t train loss: 0.0909 train acc: 72.915% test acc: 43.546%\n"
     ]
    }
   ],
   "source": [
    "# model, learning_rate = \"AdaptableLSTM\", .025\n",
    "model, learning_rate = \"BasicNN\", .0054\n",
    "# model, learning_rate = \"LogisticRegressor\", .003\n",
    "epochs = 1000\n",
    "seed = 1\n",
    "include_state = True\n",
    "estate = True\n",
    "fullq = True\n",
    "respond_perc = .50\n",
    "fullseq = True\n",
    "insertpreds = True\n",
    "noise = 0\n",
    "smooth = .1\n",
    "\n",
    "    \n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "e = Experiment(\n",
    "    numValFolds = 5,\n",
    "    epochsToUpdateLabelMods = 10,\n",
    "    data_kw={\"minw\": 2,\n",
    "            \"maxw\": 31,\n",
    "            \"include_state\": include_state,\n",
    "            \"include_pid\": False,\n",
    "            \"expanded_states\": estate,\n",
    "            \"top_respond_perc\": respond_perc,\n",
    "             \"full_questionnaire\": fullq,\n",
    "             \"full_sequence\": fullseq,\n",
    "             \"insert_predictions\": insertpreds,\n",
    "             \"one_hot_response_features\": False,\n",
    "             \"response_feature_noise\": noise\n",
    "            },\n",
    "    model=model,\n",
    "    model_kw={\n",
    "        \"lossfn\": \"MSELoss\",\n",
    "        # \"lossfn\": \"NDCG\",\n",
    "        # \"lossfn\": \"CrossEntropyLoss\",\n",
    "        \"hidden_size\": 15,\n",
    "        \"lr_step_mult\": .9, \n",
    "        \"lr_step_epochs\": 100,\n",
    "        \"opt_kw\": {\n",
    "            \"lr\": learning_rate,\n",
    "        },\n",
    "        \"labelSmoothPerc\": smooth,\n",
    "        \"gaussianNoiseStd\": noise\n",
    "        \n",
    "    },\n",
    "    train_kw={\n",
    "        \"epochs\": epochs,\n",
    "        \"n_subj\": 500,\n",
    "        \"rec_every\": 5,\n",
    "    })\n",
    "\n",
    "\n",
    "print(len(e.bd.test))\n",
    "print(len(e.bd.train))\n",
    "\n",
    "report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de6743-690e-463b-b5b0-212eb0da9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (np.mean(report['train_metrics'], axis=0))\n",
    "labels = report[\"metric_labels\"]\n",
    "print(report['train_metrics'][-1, labels.index(\"Acc\")])\n",
    "print(report['test_metrics'][-1, labels.index(\"Acc\")])\n",
    "\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "plt.title(\"Train/Test Performance Over Training\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.savefig(\"simpleNotebookAccPlot.png\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5928e0-08ac-4055-9bc6-89fe1fea6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e.bd.features.shape, e.bd.featureList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41511c-c598-4167-9570-c6b6a75c927a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
