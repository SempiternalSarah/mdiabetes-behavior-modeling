{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_1_q1' 'response_last_1_q1'\n",
      " 'response_last_1_q1' 'pmsg_sids_last_0_q1' 'pmsg_sids_last_0_q1'\n",
      " 'pmsg_sids_last_0_q1' 'pmsg_sids_last_0_q1' 'pmsg_sids_last_0_q1'\n",
      " 'paction_sids_last_0_q1' 'paction_sids_last_0_q1'\n",
      " 'paction_sids_last_0_q1' 'paction_sids_last_0_q1'\n",
      " 'paction_sids_last_0_q1' 'pmsg_ids_last_0_q1' 'pmsg_ids_last_0_q1'\n",
      " 'pmsg_ids_last_0_q1' 'pmsg_ids_last_0_q1' 'pmsg_ids_last_0_q1'\n",
      " 'pmsg_ids_last_0_q1' 'qids_last_0_q1' 'qids_last_0_q1' 'qids_last_0_q1'\n",
      " 'qids_last_0_q1' 'qids_last_0_q1' 'qids_last_0_q1' 'pmsg_sids_last_1_q1'\n",
      " 'pmsg_sids_last_1_q1' 'pmsg_sids_last_1_q1' 'pmsg_sids_last_1_q1'\n",
      " 'pmsg_sids_last_1_q1' 'paction_sids_last_1_q1' 'paction_sids_last_1_q1'\n",
      " 'paction_sids_last_1_q1' 'paction_sids_last_1_q1'\n",
      " 'paction_sids_last_1_q1' 'pmsg_ids_last_1_q1' 'pmsg_ids_last_1_q1'\n",
      " 'pmsg_ids_last_1_q1' 'pmsg_ids_last_1_q1' 'pmsg_ids_last_1_q1'\n",
      " 'pmsg_ids_last_1_q1' 'qids_last_1_q1' 'qids_last_1_q1' 'qids_last_1_q1'\n",
      " 'qids_last_1_q1' 'qids_last_1_q1' 'qids_last_1_q1' 'q1_cat' 'q1_cat']\n",
      "54\n",
      "214\n",
      "tensor([-0.0423,  0.1348,  0.0891]) tensor([ 0.1404,  0.0135, -0.2569]) tensor([ 0.1758, -0.1181, -0.0157])\n",
      "tensor([-0.0274,  0.0247, -0.0133])\n",
      "0\t train loss: 0.2133 train acc: 54.211% test acc: 52.191% train exerAcc: 47.718% test exerAcc: 48.077% train conAcc: 39.752% test conAcc: 43.648% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([ 0.0293, -0.0936, -0.0365]) tensor([-0.1819, -0.1723,  0.1011]) tensor([ 0.0449, -0.2650, -0.2196])\n",
      "tensor([ 0.0347, -0.0543,  0.0300])\n",
      "5\t train loss: 0.1881 train acc: 53.426% test acc: 48.539% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 37.929% test conAcc: 34.853% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([-0.0121,  0.0443, -0.0507]) tensor([-0.2173, -0.0088,  0.2291]) tensor([-0.0037, -0.1596, -0.2115])\n",
      "tensor([-0.0346,  0.0086, -0.0323])\n",
      "10\t train loss: 0.1818 train acc: 54.196% test acc: 52.125% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 39.752% test conAcc: 43.648% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([-0.1292, -0.0757,  0.0924]) tensor([-0.0518,  0.1665, -0.0483]) tensor([-0.0845, -0.1126, -0.1024])\n",
      "tensor([0.0235, 0.0031, 0.0127])\n",
      "15\t train loss: 0.1777 train acc: 57.721% test acc: 55.246% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 47.775% test conAcc: 51.466% train knowAcc: 66.202% test knowAcc: 58.571%\n",
      "tensor([-0.0261, -0.0582,  0.0384]) tensor([ 0.1550, -0.0460, -0.2294]) tensor([-0.1413, -0.0935,  0.0168])\n",
      "tensor([-0.0120, -0.0116,  0.0009])\n",
      "20\t train loss: 0.1785 train acc: 54.750% test acc: 50.465% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 41.028% test conAcc: 38.925% train knowAcc: 65.974% test knowAcc: 59.167%\n",
      "tensor([ 0.0574,  0.1521, -0.1243]) tensor([ 0.2359, -0.2577, -0.2795]) tensor([-0.0208, -0.0084,  0.1258])\n",
      "tensor([0.0399, 0.0510, 0.0317])\n",
      "25\t train loss: 0.1751 train acc: 57.614% test acc: 53.785% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 47.848% test conAcc: 47.720% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([0.0432, 0.1200, 0.0064]) tensor([ 0.1481, -0.2928, -0.1826]) tensor([0.1093, 0.0380, 0.1492])\n",
      "tensor([-0.0245, -0.0186, -0.0097])\n",
      "30\t train loss: 0.1735 train acc: 58.768% test acc: 55.378% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 50.584% test conAcc: 51.629% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([0.1273, 0.0456, 0.1585]) tensor([ 0.1692, -0.2072, -0.0908]) tensor([0.2055, 0.0488, 0.1189])\n",
      "tensor([0.0505, 0.0389, 0.0396])\n",
      "35\t train loss: 0.1804 train acc: 58.891% test acc: 55.511% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 50.875% test conAcc: 51.954% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([ 0.0475,  0.0135, -0.0071]) tensor([ 0.2814, -0.0388, -0.2036]) tensor([0.2382, 0.0154, 0.0894])\n",
      "tensor([-0.0120,  0.0264,  0.0107])\n",
      "40\t train loss: 0.1726 train acc: 59.276% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.787% test conAcc: 51.792% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([ 0.1378, -0.0181, -0.0840]) tensor([ 0.3159,  0.0741, -0.3454]) tensor([ 0.4058, -0.0058,  0.1371])\n",
      "tensor([ 0.0202, -0.0006,  0.0081])\n",
      "45\t train loss: 0.1698 train acc: 58.784% test acc: 54.781% train exerAcc: 46.888% test exerAcc: 44.231% train conAcc: 50.656% test conAcc: 50.326% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.2193, -0.0143,  0.0495])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "50\t train loss: 0.1739 train acc: 59.261% test acc: 55.710% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 65.945% test knowAcc: 58.690%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1543, -0.0236, -0.0737])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "55\t train loss: 0.1737 train acc: 59.292% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.002% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.2097, -0.0416, -0.1696])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "60\t train loss: 0.1731 train acc: 59.246% test acc: 55.378% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 65.917% test knowAcc: 58.095%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.2058, -0.0513, -0.0971])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "65\t train loss: 0.1728 train acc: 59.246% test acc: 55.644% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 65.917% test knowAcc: 58.571%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1860, -0.0547,  0.0222])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "70\t train loss: 0.1726 train acc: 59.353% test acc: 55.511% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.116% test knowAcc: 58.333%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1882, -0.0548,  0.1005])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "75\t train loss: 0.1725 train acc: 59.323% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.059% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1943, -0.0520,  0.1363])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "80\t train loss: 0.1725 train acc: 59.353% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.116% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1631, -0.0454,  0.1698])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "85\t train loss: 0.1725 train acc: 59.384% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.173% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1458, -0.0406,  0.1557])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "90\t train loss: 0.1725 train acc: 59.369% test acc: 55.378% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.145% test knowAcc: 58.095%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1390, -0.0379,  0.1228])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "95\t train loss: 0.1726 train acc: 59.369% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.145% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1305, -0.0368,  0.1010])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "100\t train loss: 0.1726 train acc: 59.369% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.145% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1297, -0.0374,  0.0864])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "105\t train loss: 0.1726 train acc: 59.384% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.173% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1352, -0.0389,  0.0822])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "110\t train loss: 0.1726 train acc: 59.369% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.145% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1416, -0.0403,  0.0877])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "115\t train loss: 0.1726 train acc: 59.369% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.145% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1466, -0.0411,  0.0963])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "120\t train loss: 0.1726 train acc: 59.384% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.173% test knowAcc: 58.214%\n",
      "tensor([-0.0564, -0.0179,  0.0520]) tensor([ 0.2242,  0.0804, -0.3532]) tensor([ 0.1506, -0.0414,  0.1025])\n",
      "tensor([0.0164, 0.0131, 0.0166])\n",
      "125\t train loss: 0.1726 train acc: 59.369% test acc: 55.445% train exerAcc: 47.303% test exerAcc: 46.154% train conAcc: 51.751% test conAcc: 52.443% train knowAcc: 66.145% test knowAcc: 58.214%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_50068\\2229968006.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m# torch.autograd.set_detect_anomaly(True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\experiment.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"_kw\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;31m# results = self.evaluate()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_kw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\experiment.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainPhysical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainPhysical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m             \u001b[0mlh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;31m# update our predictions as features when appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\experiment.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self, opts)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mloss1\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m             \u001b[0mloss1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainConsumption\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainKnowledge\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainPhysical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[1;31m# print(\"????\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\mdiabetes\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\mdiabetes\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model, learning_rate = \"BasicNNSplit\", .006\n",
    "# model, learning_rate = \"BasicNN\", .0054\n",
    "# model, learning_rate = \"LogisticRegressor\", .003\n",
    "model, learning_rate = \"AdaptableLSTM\", .1\n",
    "epochs = 1000\n",
    "seed = 2\n",
    "include_state = True\n",
    "estate = True\n",
    "fullq = False\n",
    "respond_perc = .50\n",
    "# number of weeks history to include as features\n",
    "numWeeks = 2\n",
    "insertpreds = False\n",
    "noise = 0.00\n",
    "smooth = 0\n",
    "# one question = one row if true\n",
    "splitQs = True\n",
    "# uses separate layers (or whole models if not LSTM) for question categories\n",
    "splitModel = True\n",
    "\n",
    "# format for these is [offEpoch, onEpoch, offEpoch, onEpoch, offEpoch....]\n",
    "# toggles training the category at every epoch in the list\n",
    "# if any category is disabled, LSTM block will be frozen\n",
    "knowSched = [1000]\n",
    "physSched = [50]\n",
    "conSched = [50]\n",
    "\n",
    "    \n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "e = Experiment(\n",
    "    modelSplit = splitModel,\n",
    "    numValFolds = 5,\n",
    "    epochsToUpdateLabelMods = 10,\n",
    "    knowSchedule = knowSched,\n",
    "    consumpSchedule = conSched,\n",
    "    physSchedule = physSched,\n",
    "    data_kw={\"minw\": 2,\n",
    "            \"maxw\": 31,\n",
    "            \"include_state\": include_state,\n",
    "            \"include_pid\": False,\n",
    "            \"expanded_states\": estate,\n",
    "            \"top_respond_perc\": respond_perc,\n",
    "             \"full_questionnaire\": fullq,\n",
    "             \"num_weeks_history\": numWeeks,\n",
    "             \"insert_predictions\": insertpreds,\n",
    "             \"one_hot_response_features\": True,\n",
    "             \"response_feature_noise\": noise,\n",
    "             \"max_state_week\": 1,\n",
    "             \"split_model_features\": splitModel,\n",
    "             \"split_weekly_questions\": splitQs\n",
    "            },\n",
    "    model=model,\n",
    "    model_kw={\n",
    "        \"lossfn\": \"MSELoss\",\n",
    "        # \"lossfn\": \"NDCG\",\n",
    "        # \"lossfn\": \"CrossEntropyLoss\",\n",
    "        \"hidden_size\": 10,\n",
    "        \"lr_step_mult\": .9, \n",
    "        \"lr_step_epochs\": 100,\n",
    "        \"opt_kw\": {\n",
    "            \"lr\": learning_rate,\n",
    "            \"weight_decay\": .001\n",
    "        },\n",
    "        \"splitModel\": splitModel,\n",
    "        \"splitWeeklyQuestions\": splitQs,\n",
    "        \"labelSmoothPerc\": smooth,\n",
    "        \"gaussianNoiseStd\": noise\n",
    "        \n",
    "    },\n",
    "    train_kw={\n",
    "        \"epochs\": epochs,\n",
    "        \"n_subj\": 500,\n",
    "        \"rec_every\": 5,\n",
    "    })\n",
    "\n",
    "\n",
    "print(len(e.bd.test))\n",
    "print(len(e.bd.train))\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de6743-690e-463b-b5b0-212eb0da9165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (np.mean(report['train_metrics'], axis=0))\n",
    "labels = report[\"metric_labels\"]\n",
    "print(report['train_metrics'][-1, labels.index(\"Acc\")])\n",
    "print(report['test_metrics'][-1, labels.index(\"Acc\")])\n",
    "\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "plt.title(\"Train/Test Performance Over Training\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.xlabel(\"Training Epoch\")\n",
    "plt.savefig(\"simpleNotebookAccPlot.png\")\n",
    "\n",
    "plt.clf()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5928e0-08ac-4055-9bc6-89fe1fea6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(e.bd.features.shape, e.bd.featureList.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a41511c-c598-4167-9570-c6b6a75c927a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
