{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.1883 train acc: 54.581% test acc: 56.349% train exerAcc: 45.217% test exerAcc: 38.095%\n",
      "5\t train loss: 0.1676 train acc: 57.331% test acc: 59.768% train exerAcc: 47.391% test exerAcc: 52.381%\n",
      "10\t train loss: 0.1606 train acc: 57.111% test acc: 60.745% train exerAcc: 48.696% test exerAcc: 52.381%\n",
      "15\t train loss: 0.1567 train acc: 57.646% test acc: 60.806% train exerAcc: 50.000% test exerAcc: 46.032%\n",
      "20\t train loss: 0.1547 train acc: 57.787% test acc: 60.806% train exerAcc: 51.304% test exerAcc: 47.619%\n",
      "25\t train loss: 0.1522 train acc: 58.117% test acc: 61.233% train exerAcc: 50.870% test exerAcc: 46.032%\n",
      "30\t train loss: 0.1668 train acc: 58.667% test acc: 61.050% train exerAcc: 50.000% test exerAcc: 46.032%\n",
      "35\t train loss: 0.1659 train acc: 58.793% test acc: 61.600% train exerAcc: 51.304% test exerAcc: 46.032%\n",
      "40\t train loss: 0.1650 train acc: 58.934% test acc: 60.867% train exerAcc: 50.000% test exerAcc: 46.032%\n",
      "45\t train loss: 0.1629 train acc: 58.982% test acc: 61.050% train exerAcc: 50.870% test exerAcc: 46.032%\n",
      "50\t train loss: 0.1620 train acc: 59.154% test acc: 61.538% train exerAcc: 50.000% test exerAcc: 46.032%\n",
      "55\t train loss: 0.1605 train acc: 59.375% test acc: 61.661% train exerAcc: 50.435% test exerAcc: 46.032%\n",
      "60\t train loss: 0.1598 train acc: 59.736% test acc: 61.722% train exerAcc: 50.870% test exerAcc: 46.032%\n",
      "65\t train loss: 0.1577 train acc: 60.097% test acc: 61.416% train exerAcc: 51.739% test exerAcc: 46.032%\n",
      "70\t train loss: 0.1563 train acc: 60.317% test acc: 61.722% train exerAcc: 51.304% test exerAcc: 46.032%\n",
      "75\t train loss: 0.1551 train acc: 60.490% test acc: 62.149% train exerAcc: 50.870% test exerAcc: 46.032%\n",
      "80\t train loss: 0.1541 train acc: 60.679% test acc: 62.027% train exerAcc: 49.130% test exerAcc: 46.032%\n",
      "85\t train loss: 0.1539 train acc: 60.836% test acc: 62.088% train exerAcc: 50.870% test exerAcc: 46.032%\n",
      "90\t train loss: 0.1531 train acc: 60.930% test acc: 62.332% train exerAcc: 50.435% test exerAcc: 46.032%\n",
      "95\t train loss: 0.1508 train acc: 61.119% test acc: 62.271% train exerAcc: 50.000% test exerAcc: 46.032%\n",
      "100\t train loss: 0.1600 train acc: 61.276% test acc: 62.088% train exerAcc: 49.565% test exerAcc: 49.206%\n",
      "105\t train loss: 0.1570 train acc: 60.899% test acc: 62.332% train exerAcc: 51.739% test exerAcc: 50.794%\n",
      "110\t train loss: 0.1569 train acc: 61.103% test acc: 61.844% train exerAcc: 55.217% test exerAcc: 49.206%\n",
      "115\t train loss: 0.1521 train acc: 61.025% test acc: 62.027% train exerAcc: 53.913% test exerAcc: 49.206%\n",
      "120\t train loss: 0.1526 train acc: 60.899% test acc: 61.905% train exerAcc: 54.783% test exerAcc: 49.206%\n",
      "125\t train loss: 0.1510 train acc: 61.119% test acc: 61.905% train exerAcc: 58.261% test exerAcc: 50.794%\n",
      "130\t train loss: 0.1501 train acc: 60.962% test acc: 61.722% train exerAcc: 56.087% test exerAcc: 49.206%\n",
      "135\t train loss: 0.1468 train acc: 60.868% test acc: 61.722% train exerAcc: 56.522% test exerAcc: 46.032%\n",
      "140\t train loss: 0.1473 train acc: 60.978% test acc: 61.905% train exerAcc: 56.087% test exerAcc: 52.381%\n",
      "145\t train loss: 0.1435 train acc: 60.883% test acc: 61.783% train exerAcc: 56.522% test exerAcc: 47.619%\n",
      "150\t train loss: 0.1462 train acc: 60.946% test acc: 61.905% train exerAcc: 56.522% test exerAcc: 50.794%\n",
      "155\t train loss: 0.1430 train acc: 61.025% test acc: 61.966% train exerAcc: 58.696% test exerAcc: 53.968%\n",
      "160\t train loss: 0.1429 train acc: 60.962% test acc: 62.088% train exerAcc: 59.130% test exerAcc: 53.968%\n",
      "165\t train loss: 0.1410 train acc: 61.056% test acc: 61.844% train exerAcc: 59.565% test exerAcc: 52.381%\n",
      "170\t train loss: 0.1397 train acc: 61.103% test acc: 61.844% train exerAcc: 60.000% test exerAcc: 53.968%\n",
      "175\t train loss: 0.1373 train acc: 60.978% test acc: 61.905% train exerAcc: 58.696% test exerAcc: 52.381%\n",
      "180\t train loss: 0.1377 train acc: 61.135% test acc: 62.088% train exerAcc: 60.435% test exerAcc: 53.968%\n",
      "185\t train loss: 0.1352 train acc: 61.103% test acc: 61.966% train exerAcc: 61.304% test exerAcc: 53.968%\n",
      "190\t train loss: 0.1346 train acc: 61.182% test acc: 61.783% train exerAcc: 60.870% test exerAcc: 50.794%\n",
      "195\t train loss: 0.1342 train acc: 60.962% test acc: 62.149% train exerAcc: 60.000% test exerAcc: 53.968%\n",
      "200\t train loss: 0.1331 train acc: 61.072% test acc: 61.722% train exerAcc: 60.000% test exerAcc: 49.206%\n",
      "205\t train loss: 0.1336 train acc: 61.056% test acc: 62.210% train exerAcc: 59.565% test exerAcc: 52.381%\n",
      "210\t train loss: 0.1337 train acc: 61.213% test acc: 62.271% train exerAcc: 60.000% test exerAcc: 53.968%\n",
      "215\t train loss: 0.1325 train acc: 61.103% test acc: 62.027% train exerAcc: 60.435% test exerAcc: 52.381%\n",
      "220\t train loss: 0.1319 train acc: 61.103% test acc: 61.905% train exerAcc: 59.130% test exerAcc: 50.794%\n",
      "225\t train loss: 0.1323 train acc: 61.056% test acc: 62.027% train exerAcc: 59.130% test exerAcc: 52.381%\n",
      "230\t train loss: 0.1318 train acc: 61.135% test acc: 62.027% train exerAcc: 60.435% test exerAcc: 52.381%\n",
      "235\t train loss: 0.1319 train acc: 61.276% test acc: 62.088% train exerAcc: 60.000% test exerAcc: 50.794%\n",
      "240\t train loss: 0.1322 train acc: 61.056% test acc: 61.783% train exerAcc: 59.565% test exerAcc: 50.794%\n",
      "245\t train loss: 0.1318 train acc: 61.135% test acc: 61.844% train exerAcc: 59.565% test exerAcc: 50.794%\n",
      "250\t train loss: 0.1313 train acc: 61.150% test acc: 62.149% train exerAcc: 60.435% test exerAcc: 52.381%\n",
      "255\t train loss: 0.1320 train acc: 61.166% test acc: 61.966% train exerAcc: 59.130% test exerAcc: 52.381%\n",
      "260\t train loss: 0.1317 train acc: 60.993% test acc: 62.027% train exerAcc: 60.000% test exerAcc: 52.381%\n",
      "265\t train loss: 0.1320 train acc: 61.040% test acc: 61.722% train exerAcc: 59.565% test exerAcc: 50.794%\n",
      "270\t train loss: 0.1316 train acc: 61.135% test acc: 61.844% train exerAcc: 60.870% test exerAcc: 50.794%\n",
      "275\t train loss: 0.1319 train acc: 61.025% test acc: 61.844% train exerAcc: 58.696% test exerAcc: 52.381%\n",
      "280\t train loss: 0.1312 train acc: 61.166% test acc: 62.027% train exerAcc: 60.000% test exerAcc: 52.381%\n",
      "285\t train loss: 0.1306 train acc: 61.056% test acc: 61.661% train exerAcc: 60.435% test exerAcc: 50.794%\n",
      "290\t train loss: 0.1314 train acc: 61.229% test acc: 61.783% train exerAcc: 59.565% test exerAcc: 50.794%\n",
      "295\t train loss: 0.1304 train acc: 61.245% test acc: 61.905% train exerAcc: 60.870% test exerAcc: 50.794%\n",
      "299\t train loss: 0.1311 train acc: 61.355% test acc: 61.538% train exerAcc: 59.130% test exerAcc: 50.794%\n",
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.2018 train acc: 16.747% test acc: 15.318% train exerAcc: 26.432% test exerAcc: 19.697%\n",
      "5\t train loss: 0.1810 train acc: 53.212% test acc: 51.922% train exerAcc: 49.339% test exerAcc: 48.485%\n",
      "10\t train loss: 0.1679 train acc: 54.155% test acc: 52.840% train exerAcc: 49.339% test exerAcc: 46.970%\n",
      "15\t train loss: 0.1612 train acc: 58.421% test acc: 57.889% train exerAcc: 47.577% test exerAcc: 51.515%\n",
      "20\t train loss: 0.1575 train acc: 58.373% test acc: 57.602% train exerAcc: 49.780% test exerAcc: 50.000%\n",
      "25\t train loss: 0.1545 train acc: 58.245% test acc: 57.659% train exerAcc: 51.101% test exerAcc: 53.030%\n",
      "30\t train loss: 0.1677 train acc: 58.405% test acc: 57.717% train exerAcc: 53.304% test exerAcc: 56.061%\n",
      "35\t train loss: 0.1673 train acc: 58.917% test acc: 57.717% train exerAcc: 52.863% test exerAcc: 54.545%\n",
      "40\t train loss: 0.1657 train acc: 59.444% test acc: 58.520% train exerAcc: 51.542% test exerAcc: 51.515%\n",
      "45\t train loss: 0.1647 train acc: 59.236% test acc: 57.831% train exerAcc: 51.542% test exerAcc: 50.000%\n",
      "50\t train loss: 0.1639 train acc: 59.220% test acc: 57.889% train exerAcc: 49.780% test exerAcc: 51.515%\n",
      "55\t train loss: 0.1625 train acc: 59.476% test acc: 58.118% train exerAcc: 51.542% test exerAcc: 50.000%\n",
      "60\t train loss: 0.1614 train acc: 59.811% test acc: 58.577% train exerAcc: 51.542% test exerAcc: 50.000%\n",
      "65\t train loss: 0.1609 train acc: 60.003% test acc: 58.577% train exerAcc: 51.542% test exerAcc: 48.485%\n",
      "70\t train loss: 0.1597 train acc: 60.275% test acc: 58.635% train exerAcc: 50.661% test exerAcc: 50.000%\n",
      "75\t train loss: 0.1581 train acc: 60.291% test acc: 58.921% train exerAcc: 48.899% test exerAcc: 48.485%\n",
      "80\t train loss: 0.1573 train acc: 60.531% test acc: 58.979% train exerAcc: 50.220% test exerAcc: 50.000%\n",
      "85\t train loss: 0.1565 train acc: 60.754% test acc: 58.807% train exerAcc: 50.661% test exerAcc: 50.000%\n",
      "90\t train loss: 0.1557 train acc: 60.898% test acc: 58.921% train exerAcc: 50.661% test exerAcc: 50.000%\n",
      "95\t train loss: 0.1550 train acc: 61.154% test acc: 58.635% train exerAcc: 51.982% test exerAcc: 50.000%\n",
      "100\t train loss: 0.1660 train acc: 61.122% test acc: 58.864% train exerAcc: 50.661% test exerAcc: 51.515%\n",
      "105\t train loss: 0.1594 train acc: 60.882% test acc: 58.921% train exerAcc: 49.339% test exerAcc: 46.970%\n",
      "110\t train loss: 0.1588 train acc: 60.914% test acc: 58.577% train exerAcc: 54.185% test exerAcc: 46.970%\n",
      "115\t train loss: 0.1534 train acc: 60.818% test acc: 58.807% train exerAcc: 51.542% test exerAcc: 48.485%\n",
      "120\t train loss: 0.1560 train acc: 60.962% test acc: 58.692% train exerAcc: 55.066% test exerAcc: 48.485%\n",
      "125\t train loss: 0.1561 train acc: 61.090% test acc: 58.520% train exerAcc: 57.709% test exerAcc: 45.455%\n",
      "130\t train loss: 0.1528 train acc: 61.026% test acc: 58.348% train exerAcc: 57.709% test exerAcc: 45.455%\n",
      "135\t train loss: 0.1520 train acc: 61.122% test acc: 58.405% train exerAcc: 59.031% test exerAcc: 43.939%\n",
      "140\t train loss: 0.1511 train acc: 60.962% test acc: 58.577% train exerAcc: 59.031% test exerAcc: 46.970%\n",
      "145\t train loss: 0.1529 train acc: 61.058% test acc: 58.577% train exerAcc: 58.590% test exerAcc: 48.485%\n",
      "150\t train loss: 0.1508 train acc: 61.026% test acc: 58.749% train exerAcc: 59.471% test exerAcc: 46.970%\n",
      "155\t train loss: 0.1505 train acc: 61.090% test acc: 58.749% train exerAcc: 60.352% test exerAcc: 48.485%\n",
      "160\t train loss: 0.1459 train acc: 61.138% test acc: 58.635% train exerAcc: 60.352% test exerAcc: 48.485%\n",
      "165\t train loss: 0.1472 train acc: 61.106% test acc: 58.864% train exerAcc: 60.352% test exerAcc: 48.485%\n",
      "170\t train loss: 0.1464 train acc: 61.202% test acc: 58.577% train exerAcc: 61.233% test exerAcc: 46.970%\n",
      "175\t train loss: 0.1426 train acc: 61.202% test acc: 58.921% train exerAcc: 61.233% test exerAcc: 48.485%\n",
      "180\t train loss: 0.1432 train acc: 61.393% test acc: 58.921% train exerAcc: 61.233% test exerAcc: 48.485%\n",
      "185\t train loss: 0.1384 train acc: 60.770% test acc: 59.495% train exerAcc: 60.793% test exerAcc: 46.970%\n",
      "190\t train loss: 0.1350 train acc: 61.282% test acc: 59.208% train exerAcc: 59.471% test exerAcc: 48.485%\n",
      "195\t train loss: 0.1346 train acc: 61.250% test acc: 58.864% train exerAcc: 59.031% test exerAcc: 42.424%\n",
      "200\t train loss: 0.1338 train acc: 61.298% test acc: 58.864% train exerAcc: 60.352% test exerAcc: 46.970%\n",
      "205\t train loss: 0.1313 train acc: 61.425% test acc: 58.979% train exerAcc: 60.793% test exerAcc: 45.455%\n",
      "210\t train loss: 0.1314 train acc: 61.425% test acc: 58.864% train exerAcc: 59.912% test exerAcc: 48.485%\n",
      "215\t train loss: 0.1310 train acc: 61.250% test acc: 59.266% train exerAcc: 59.471% test exerAcc: 46.970%\n",
      "220\t train loss: 0.1310 train acc: 61.441% test acc: 58.864% train exerAcc: 62.555% test exerAcc: 42.424%\n",
      "225\t train loss: 0.1308 train acc: 61.425% test acc: 58.807% train exerAcc: 60.793% test exerAcc: 45.455%\n",
      "230\t train loss: 0.1299 train acc: 61.441% test acc: 58.921% train exerAcc: 59.471% test exerAcc: 43.939%\n",
      "235\t train loss: 0.1296 train acc: 61.393% test acc: 59.094% train exerAcc: 60.793% test exerAcc: 43.939%\n",
      "240\t train loss: 0.1306 train acc: 61.537% test acc: 59.094% train exerAcc: 61.674% test exerAcc: 48.485%\n",
      "245\t train loss: 0.1304 train acc: 61.537% test acc: 58.864% train exerAcc: 61.233% test exerAcc: 48.485%\n",
      "250\t train loss: 0.1297 train acc: 61.505% test acc: 59.036% train exerAcc: 61.233% test exerAcc: 43.939%\n",
      "255\t train loss: 0.1294 train acc: 61.553% test acc: 59.094% train exerAcc: 60.793% test exerAcc: 48.485%\n",
      "260\t train loss: 0.1295 train acc: 61.553% test acc: 59.094% train exerAcc: 61.233% test exerAcc: 46.970%\n",
      "265\t train loss: 0.1296 train acc: 61.505% test acc: 59.094% train exerAcc: 60.793% test exerAcc: 48.485%\n",
      "270\t train loss: 0.1301 train acc: 61.633% test acc: 58.979% train exerAcc: 62.115% test exerAcc: 46.970%\n",
      "275\t train loss: 0.1297 train acc: 61.457% test acc: 59.266% train exerAcc: 60.793% test exerAcc: 48.485%\n",
      "280\t train loss: 0.1300 train acc: 61.505% test acc: 58.807% train exerAcc: 60.793% test exerAcc: 42.424%\n",
      "285\t train loss: 0.1290 train acc: 61.473% test acc: 58.921% train exerAcc: 60.793% test exerAcc: 43.939%\n",
      "290\t train loss: 0.1290 train acc: 61.441% test acc: 58.979% train exerAcc: 61.674% test exerAcc: 46.970%\n",
      "295\t train loss: 0.1301 train acc: 61.521% test acc: 58.979% train exerAcc: 61.674% test exerAcc: 48.485%\n",
      "299\t train loss: 0.1294 train acc: 61.489% test acc: 58.864% train exerAcc: 60.793% test exerAcc: 43.939%\n",
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.1961 train acc: 45.681% test acc: 42.297% train exerAcc: 48.133% test exerAcc: 50.000%\n",
      "5\t train loss: 0.1671 train acc: 58.183% test acc: 55.511% train exerAcc: 48.133% test exerAcc: 50.000%\n",
      "10\t train loss: 0.1607 train acc: 57.691% test acc: 54.847% train exerAcc: 48.963% test exerAcc: 50.000%\n",
      "15\t train loss: 0.1577 train acc: 58.553% test acc: 55.511% train exerAcc: 49.378% test exerAcc: 53.846%\n",
      "20\t train loss: 0.1544 train acc: 59.076% test acc: 55.644% train exerAcc: 52.282% test exerAcc: 48.077%\n",
      "25\t train loss: 0.1508 train acc: 58.830% test acc: 55.644% train exerAcc: 50.622% test exerAcc: 50.000%\n",
      "30\t train loss: 0.1680 train acc: 59.107% test acc: 56.175% train exerAcc: 54.772% test exerAcc: 50.000%\n",
      "35\t train loss: 0.1671 train acc: 59.430% test acc: 55.843% train exerAcc: 54.357% test exerAcc: 48.077%\n",
      "40\t train loss: 0.1657 train acc: 59.630% test acc: 55.644% train exerAcc: 56.017% test exerAcc: 51.923%\n",
      "45\t train loss: 0.1629 train acc: 60.216% test acc: 55.578% train exerAcc: 53.527% test exerAcc: 53.846%\n",
      "50\t train loss: 0.1626 train acc: 60.293% test acc: 56.175% train exerAcc: 53.527% test exerAcc: 51.923%\n",
      "55\t train loss: 0.1613 train acc: 60.262% test acc: 56.375% train exerAcc: 52.282% test exerAcc: 51.923%\n",
      "60\t train loss: 0.1597 train acc: 60.708% test acc: 56.308% train exerAcc: 52.282% test exerAcc: 51.923%\n",
      "65\t train loss: 0.1593 train acc: 60.924% test acc: 56.906% train exerAcc: 52.282% test exerAcc: 51.923%\n",
      "70\t train loss: 0.1584 train acc: 61.078% test acc: 56.707% train exerAcc: 52.282% test exerAcc: 50.000%\n",
      "75\t train loss: 0.1568 train acc: 61.247% test acc: 56.972% train exerAcc: 51.037% test exerAcc: 50.000%\n",
      "80\t train loss: 0.1565 train acc: 61.524% test acc: 56.507% train exerAcc: 51.452% test exerAcc: 50.000%\n",
      "85\t train loss: 0.1554 train acc: 61.647% test acc: 56.109% train exerAcc: 51.867% test exerAcc: 50.000%\n",
      "90\t train loss: 0.1550 train acc: 61.493% test acc: 55.910% train exerAcc: 51.867% test exerAcc: 50.000%\n",
      "95\t train loss: 0.1533 train acc: 61.909% test acc: 55.976% train exerAcc: 53.527% test exerAcc: 50.000%\n",
      "100\t train loss: 0.1612 train acc: 62.171% test acc: 55.976% train exerAcc: 56.432% test exerAcc: 53.846%\n",
      "105\t train loss: 0.1583 train acc: 61.909% test acc: 55.910% train exerAcc: 54.772% test exerAcc: 50.000%\n",
      "110\t train loss: 0.1586 train acc: 61.863% test acc: 56.042% train exerAcc: 55.187% test exerAcc: 50.000%\n",
      "115\t train loss: 0.1561 train acc: 61.786% test acc: 55.910% train exerAcc: 54.357% test exerAcc: 51.923%\n",
      "120\t train loss: 0.1513 train acc: 61.863% test acc: 56.175% train exerAcc: 57.676% test exerAcc: 53.846%\n",
      "125\t train loss: 0.1567 train acc: 61.971% test acc: 56.109% train exerAcc: 57.676% test exerAcc: 50.000%\n",
      "130\t train loss: 0.1523 train acc: 61.971% test acc: 55.976% train exerAcc: 55.602% test exerAcc: 53.846%\n",
      "135\t train loss: 0.1527 train acc: 62.017% test acc: 55.644% train exerAcc: 58.506% test exerAcc: 50.000%\n",
      "140\t train loss: 0.1512 train acc: 61.925% test acc: 56.175% train exerAcc: 58.091% test exerAcc: 51.923%\n",
      "145\t train loss: 0.1450 train acc: 62.017% test acc: 56.175% train exerAcc: 58.921% test exerAcc: 53.846%\n",
      "150\t train loss: 0.1458 train acc: 62.063% test acc: 56.042% train exerAcc: 60.166% test exerAcc: 55.769%\n",
      "155\t train loss: 0.1478 train acc: 62.032% test acc: 55.976% train exerAcc: 60.166% test exerAcc: 53.846%\n",
      "160\t train loss: 0.1462 train acc: 62.202% test acc: 55.976% train exerAcc: 60.996% test exerAcc: 51.923%\n",
      "165\t train loss: 0.1466 train acc: 62.263% test acc: 56.042% train exerAcc: 61.411% test exerAcc: 53.846%\n",
      "170\t train loss: 0.1449 train acc: 61.986% test acc: 55.910% train exerAcc: 59.751% test exerAcc: 51.923%\n",
      "175\t train loss: 0.1453 train acc: 62.063% test acc: 55.976% train exerAcc: 59.751% test exerAcc: 50.000%\n",
      "180\t train loss: 0.1341 train acc: 62.171% test acc: 55.910% train exerAcc: 60.166% test exerAcc: 50.000%\n",
      "185\t train loss: 0.1314 train acc: 62.125% test acc: 55.777% train exerAcc: 61.411% test exerAcc: 51.923%\n",
      "190\t train loss: 0.1292 train acc: 62.048% test acc: 56.042% train exerAcc: 60.581% test exerAcc: 53.846%\n",
      "195\t train loss: 0.1286 train acc: 62.109% test acc: 56.042% train exerAcc: 60.166% test exerAcc: 55.769%\n",
      "200\t train loss: 0.1283 train acc: 62.063% test acc: 55.976% train exerAcc: 60.581% test exerAcc: 57.692%\n",
      "205\t train loss: 0.1281 train acc: 62.079% test acc: 55.910% train exerAcc: 59.336% test exerAcc: 55.769%\n",
      "210\t train loss: 0.1272 train acc: 62.094% test acc: 56.242% train exerAcc: 59.336% test exerAcc: 57.692%\n",
      "215\t train loss: 0.1273 train acc: 62.063% test acc: 56.109% train exerAcc: 60.581% test exerAcc: 53.846%\n",
      "220\t train loss: 0.1264 train acc: 62.109% test acc: 56.375% train exerAcc: 60.166% test exerAcc: 59.615%\n",
      "225\t train loss: 0.1270 train acc: 61.986% test acc: 56.375% train exerAcc: 59.751% test exerAcc: 57.692%\n",
      "230\t train loss: 0.1267 train acc: 62.248% test acc: 56.109% train exerAcc: 60.166% test exerAcc: 55.769%\n",
      "235\t train loss: 0.1265 train acc: 62.248% test acc: 56.441% train exerAcc: 59.751% test exerAcc: 55.769%\n",
      "240\t train loss: 0.1263 train acc: 62.125% test acc: 56.308% train exerAcc: 60.581% test exerAcc: 53.846%\n",
      "245\t train loss: 0.1260 train acc: 62.263% test acc: 56.242% train exerAcc: 58.921% test exerAcc: 55.769%\n",
      "250\t train loss: 0.1262 train acc: 62.125% test acc: 56.242% train exerAcc: 60.581% test exerAcc: 55.769%\n",
      "255\t train loss: 0.1259 train acc: 61.971% test acc: 56.109% train exerAcc: 59.336% test exerAcc: 53.846%\n",
      "260\t train loss: 0.1260 train acc: 62.325% test acc: 56.773% train exerAcc: 60.581% test exerAcc: 57.692%\n",
      "265\t train loss: 0.1264 train acc: 62.217% test acc: 56.441% train exerAcc: 60.996% test exerAcc: 55.769%\n",
      "270\t train loss: 0.1255 train acc: 62.156% test acc: 56.441% train exerAcc: 60.581% test exerAcc: 55.769%\n",
      "275\t train loss: 0.1267 train acc: 62.156% test acc: 56.375% train exerAcc: 60.581% test exerAcc: 55.769%\n",
      "280\t train loss: 0.1257 train acc: 62.156% test acc: 56.242% train exerAcc: 60.166% test exerAcc: 55.769%\n",
      "285\t train loss: 0.1254 train acc: 62.140% test acc: 56.441% train exerAcc: 60.166% test exerAcc: 57.692%\n",
      "290\t train loss: 0.1252 train acc: 62.248% test acc: 56.441% train exerAcc: 60.581% test exerAcc: 57.692%\n",
      "295\t train loss: 0.1262 train acc: 62.171% test acc: 56.441% train exerAcc: 60.166% test exerAcc: 57.692%\n",
      "299\t train loss: 0.1263 train acc: 62.109% test acc: 56.441% train exerAcc: 59.751% test exerAcc: 55.769%\n",
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.1878 train acc: 49.316% test acc: 51.343% train exerAcc: 48.696% test exerAcc: 50.794%\n",
      "5\t train loss: 0.1748 train acc: 55.336% test acc: 57.814% train exerAcc: 47.826% test exerAcc: 52.381%\n",
      "10\t train loss: 0.1689 train acc: 56.294% test acc: 58.669% train exerAcc: 47.826% test exerAcc: 52.381%\n",
      "15\t train loss: 0.1649 train acc: 56.907% test acc: 59.829% train exerAcc: 49.565% test exerAcc: 52.381%\n",
      "20\t train loss: 0.1616 train acc: 57.379% test acc: 60.745% train exerAcc: 50.000% test exerAcc: 52.381%\n",
      "25\t train loss: 0.1593 train acc: 57.599% test acc: 60.501% train exerAcc: 50.435% test exerAcc: 50.794%\n",
      "30\t train loss: 0.1757 train acc: 57.787% test acc: 60.073% train exerAcc: 50.870% test exerAcc: 47.619%\n",
      "35\t train loss: 0.1737 train acc: 57.756% test acc: 60.379% train exerAcc: 50.000% test exerAcc: 47.619%\n",
      "40\t train loss: 0.1725 train acc: 57.866% test acc: 60.440% train exerAcc: 50.435% test exerAcc: 47.619%\n",
      "45\t train loss: 0.1702 train acc: 57.866% test acc: 60.256% train exerAcc: 50.435% test exerAcc: 47.619%\n",
      "50\t train loss: 0.1697 train acc: 57.866% test acc: 60.562% train exerAcc: 50.435% test exerAcc: 47.619%\n",
      "55\t train loss: 0.1674 train acc: 57.944% test acc: 60.684% train exerAcc: 50.870% test exerAcc: 47.619%\n",
      "60\t train loss: 0.1686 train acc: 58.086% test acc: 60.989% train exerAcc: 50.870% test exerAcc: 49.206%\n",
      "65\t train loss: 0.1682 train acc: 58.070% test acc: 60.989% train exerAcc: 50.870% test exerAcc: 46.032%\n",
      "70\t train loss: 0.1673 train acc: 58.149% test acc: 61.050% train exerAcc: 51.304% test exerAcc: 46.032%\n",
      "75\t train loss: 0.1671 train acc: 58.212% test acc: 61.050% train exerAcc: 51.304% test exerAcc: 46.032%\n",
      "80\t train loss: 0.1659 train acc: 58.432% test acc: 61.172% train exerAcc: 50.435% test exerAcc: 46.032%\n",
      "85\t train loss: 0.1666 train acc: 58.542% test acc: 61.416% train exerAcc: 51.304% test exerAcc: 46.032%\n",
      "90\t train loss: 0.1663 train acc: 58.699% test acc: 61.477% train exerAcc: 50.870% test exerAcc: 47.619%\n",
      "95\t train loss: 0.1664 train acc: 58.636% test acc: 61.477% train exerAcc: 50.870% test exerAcc: 46.032%\n",
      "100\t train loss: 0.1686 train acc: 58.824% test acc: 61.477% train exerAcc: 51.304% test exerAcc: 49.206%\n",
      "105\t train loss: 0.1615 train acc: 58.793% test acc: 61.600% train exerAcc: 51.304% test exerAcc: 47.619%\n",
      "110\t train loss: 0.1616 train acc: 58.762% test acc: 61.600% train exerAcc: 51.304% test exerAcc: 47.619%\n",
      "115\t train loss: 0.1633 train acc: 58.824% test acc: 61.661% train exerAcc: 52.609% test exerAcc: 46.032%\n",
      "120\t train loss: 0.1576 train acc: 58.809% test acc: 61.844% train exerAcc: 52.174% test exerAcc: 49.206%\n",
      "125\t train loss: 0.1603 train acc: 58.856% test acc: 61.600% train exerAcc: 51.304% test exerAcc: 46.032%\n",
      "130\t train loss: 0.1596 train acc: 58.793% test acc: 61.416% train exerAcc: 52.609% test exerAcc: 47.619%\n",
      "135\t train loss: 0.1582 train acc: 58.762% test acc: 61.661% train exerAcc: 51.739% test exerAcc: 47.619%\n",
      "140\t train loss: 0.1559 train acc: 58.777% test acc: 61.783% train exerAcc: 52.174% test exerAcc: 50.794%\n",
      "145\t train loss: 0.1588 train acc: 58.919% test acc: 61.538% train exerAcc: 52.174% test exerAcc: 49.206%\n",
      "150\t train loss: 0.1593 train acc: 58.777% test acc: 61.844% train exerAcc: 52.609% test exerAcc: 49.206%\n",
      "155\t train loss: 0.1577 train acc: 58.762% test acc: 61.844% train exerAcc: 52.174% test exerAcc: 49.206%\n",
      "160\t train loss: 0.1581 train acc: 58.746% test acc: 61.966% train exerAcc: 51.739% test exerAcc: 53.968%\n",
      "165\t train loss: 0.1601 train acc: 58.840% test acc: 61.600% train exerAcc: 51.304% test exerAcc: 50.794%\n",
      "170\t train loss: 0.1583 train acc: 58.762% test acc: 61.966% train exerAcc: 51.739% test exerAcc: 53.968%\n",
      "175\t train loss: 0.1603 train acc: 58.840% test acc: 61.783% train exerAcc: 53.043% test exerAcc: 50.794%\n",
      "180\t train loss: 0.1424 train acc: 58.730% test acc: 61.905% train exerAcc: 51.739% test exerAcc: 53.968%\n",
      "185\t train loss: 0.1400 train acc: 58.762% test acc: 62.088% train exerAcc: 51.739% test exerAcc: 53.968%\n",
      "190\t train loss: 0.1403 train acc: 58.856% test acc: 61.722% train exerAcc: 53.478% test exerAcc: 52.381%\n",
      "195\t train loss: 0.1383 train acc: 58.824% test acc: 62.149% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "200\t train loss: 0.1380 train acc: 58.840% test acc: 62.210% train exerAcc: 52.174% test exerAcc: 52.381%\n",
      "205\t train loss: 0.1377 train acc: 58.966% test acc: 62.149% train exerAcc: 51.739% test exerAcc: 52.381%\n",
      "210\t train loss: 0.1365 train acc: 59.107% test acc: 62.210% train exerAcc: 53.913% test exerAcc: 49.206%\n",
      "215\t train loss: 0.1357 train acc: 59.186% test acc: 62.210% train exerAcc: 53.478% test exerAcc: 50.794%\n",
      "220\t train loss: 0.1354 train acc: 58.966% test acc: 62.332% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "225\t train loss: 0.1347 train acc: 59.123% test acc: 62.332% train exerAcc: 53.043% test exerAcc: 53.968%\n",
      "230\t train loss: 0.1349 train acc: 59.029% test acc: 62.210% train exerAcc: 53.043% test exerAcc: 53.968%\n",
      "235\t train loss: 0.1347 train acc: 59.044% test acc: 62.332% train exerAcc: 53.478% test exerAcc: 53.968%\n",
      "240\t train loss: 0.1345 train acc: 58.997% test acc: 62.332% train exerAcc: 52.174% test exerAcc: 53.968%\n",
      "245\t train loss: 0.1342 train acc: 59.044% test acc: 62.393% train exerAcc: 52.609% test exerAcc: 52.381%\n",
      "250\t train loss: 0.1339 train acc: 59.249% test acc: 62.332% train exerAcc: 53.043% test exerAcc: 52.381%\n",
      "255\t train loss: 0.1337 train acc: 59.217% test acc: 62.454% train exerAcc: 53.478% test exerAcc: 53.968%\n",
      "260\t train loss: 0.1333 train acc: 59.202% test acc: 62.332% train exerAcc: 52.174% test exerAcc: 53.968%\n",
      "265\t train loss: 0.1339 train acc: 59.154% test acc: 62.454% train exerAcc: 52.174% test exerAcc: 52.381%\n",
      "270\t train loss: 0.1331 train acc: 59.233% test acc: 62.393% train exerAcc: 53.043% test exerAcc: 53.968%\n",
      "275\t train loss: 0.1327 train acc: 59.280% test acc: 62.515% train exerAcc: 53.478% test exerAcc: 53.968%\n",
      "280\t train loss: 0.1330 train acc: 59.076% test acc: 62.515% train exerAcc: 51.304% test exerAcc: 53.968%\n",
      "285\t train loss: 0.1332 train acc: 59.264% test acc: 62.454% train exerAcc: 53.043% test exerAcc: 53.968%\n",
      "290\t train loss: 0.1336 train acc: 59.217% test acc: 62.576% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "295\t train loss: 0.1329 train acc: 59.202% test acc: 62.332% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "300\t train loss: 0.1329 train acc: 59.186% test acc: 62.332% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "305\t train loss: 0.1330 train acc: 59.233% test acc: 62.271% train exerAcc: 53.043% test exerAcc: 53.968%\n",
      "310\t train loss: 0.1324 train acc: 59.186% test acc: 62.149% train exerAcc: 52.174% test exerAcc: 50.794%\n",
      "315\t train loss: 0.1323 train acc: 59.264% test acc: 62.271% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "320\t train loss: 0.1327 train acc: 59.202% test acc: 62.271% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "325\t train loss: 0.1326 train acc: 59.170% test acc: 62.271% train exerAcc: 52.609% test exerAcc: 53.968%\n",
      "330\t train loss: 0.1326 train acc: 59.264% test acc: 62.271% train exerAcc: 53.043% test exerAcc: 53.968%\n",
      "335\t train loss: 0.1332 train acc: 59.343% test acc: 62.332% train exerAcc: 52.174% test exerAcc: 53.968%\n",
      "340\t train loss: 0.1328 train acc: 59.312% test acc: 62.149% train exerAcc: 53.043% test exerAcc: 52.381%\n",
      "345\t train loss: 0.1320 train acc: 59.217% test acc: 62.149% train exerAcc: 53.043% test exerAcc: 53.968%\n",
      "350\t train loss: 0.1321 train acc: 59.107% test acc: 62.332% train exerAcc: 53.043% test exerAcc: 52.381%\n",
      "355\t train loss: 0.1320 train acc: 59.264% test acc: 62.271% train exerAcc: 52.174% test exerAcc: 53.968%\n",
      "360\t train loss: 0.1321 train acc: 59.123% test acc: 62.210% train exerAcc: 53.478% test exerAcc: 53.968%\n",
      "365\t train loss: 0.1325 train acc: 59.217% test acc: 62.088% train exerAcc: 52.609% test exerAcc: 52.381%\n",
      "370\t train loss: 0.1323 train acc: 59.123% test acc: 62.271% train exerAcc: 52.174% test exerAcc: 52.381%\n",
      "375\t train loss: 0.1325 train acc: 59.139% test acc: 62.027% train exerAcc: 52.609% test exerAcc: 52.381%\n",
      "380\t train loss: 0.1320 train acc: 59.076% test acc: 62.027% train exerAcc: 52.174% test exerAcc: 52.381%\n",
      "385\t train loss: 0.1321 train acc: 59.249% test acc: 62.149% train exerAcc: 52.609% test exerAcc: 52.381%\n",
      "390\t train loss: 0.1313 train acc: 59.154% test acc: 62.149% train exerAcc: 52.609% test exerAcc: 52.381%\n",
      "395\t train loss: 0.1322 train acc: 59.202% test acc: 62.515% train exerAcc: 51.739% test exerAcc: 53.968%\n",
      "399\t train loss: 0.1322 train acc: 59.123% test acc: 62.332% train exerAcc: 51.739% test exerAcc: 52.381%\n",
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.1931 train acc: 36.258% test acc: 38.382% train exerAcc: 29.515% test exerAcc: 31.818%\n",
      "5\t train loss: 0.1792 train acc: 52.956% test acc: 53.471% train exerAcc: 47.137% test exerAcc: 48.485%\n",
      "10\t train loss: 0.1701 train acc: 56.568% test acc: 56.799% train exerAcc: 48.899% test exerAcc: 48.485%\n",
      "15\t train loss: 0.1656 train acc: 57.367% test acc: 57.143% train exerAcc: 49.339% test exerAcc: 48.485%\n",
      "20\t train loss: 0.1616 train acc: 58.086% test acc: 57.258% train exerAcc: 49.339% test exerAcc: 48.485%\n",
      "25\t train loss: 0.1590 train acc: 58.070% test acc: 58.003% train exerAcc: 49.339% test exerAcc: 48.485%\n",
      "30\t train loss: 0.1758 train acc: 58.309% test acc: 58.003% train exerAcc: 49.339% test exerAcc: 48.485%\n",
      "35\t train loss: 0.1749 train acc: 58.469% test acc: 58.233% train exerAcc: 50.220% test exerAcc: 48.485%\n",
      "40\t train loss: 0.1726 train acc: 58.629% test acc: 58.520% train exerAcc: 50.220% test exerAcc: 50.000%\n",
      "45\t train loss: 0.1709 train acc: 58.645% test acc: 58.405% train exerAcc: 48.899% test exerAcc: 54.545%\n",
      "50\t train loss: 0.1704 train acc: 58.869% test acc: 58.577% train exerAcc: 48.018% test exerAcc: 53.030%\n",
      "55\t train loss: 0.1696 train acc: 58.853% test acc: 58.749% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "60\t train loss: 0.1687 train acc: 58.885% test acc: 58.520% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "65\t train loss: 0.1678 train acc: 58.981% test acc: 58.520% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "70\t train loss: 0.1675 train acc: 58.981% test acc: 58.864% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "75\t train loss: 0.1674 train acc: 58.933% test acc: 58.921% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "80\t train loss: 0.1664 train acc: 58.885% test acc: 59.036% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "85\t train loss: 0.1667 train acc: 58.965% test acc: 58.807% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "90\t train loss: 0.1658 train acc: 59.044% test acc: 58.979% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "95\t train loss: 0.1657 train acc: 59.012% test acc: 59.036% train exerAcc: 47.577% test exerAcc: 53.030%\n",
      "100\t train loss: 0.1676 train acc: 59.124% test acc: 58.807% train exerAcc: 48.458% test exerAcc: 50.000%\n",
      "105\t train loss: 0.1660 train acc: 59.188% test acc: 58.979% train exerAcc: 50.220% test exerAcc: 48.485%\n",
      "110\t train loss: 0.1658 train acc: 59.220% test acc: 59.151% train exerAcc: 51.542% test exerAcc: 54.545%\n",
      "115\t train loss: 0.1599 train acc: 59.172% test acc: 58.864% train exerAcc: 50.661% test exerAcc: 48.485%\n",
      "120\t train loss: 0.1622 train acc: 59.156% test acc: 58.749% train exerAcc: 51.101% test exerAcc: 48.485%\n",
      "125\t train loss: 0.1648 train acc: 59.172% test acc: 58.864% train exerAcc: 51.982% test exerAcc: 48.485%\n",
      "130\t train loss: 0.1605 train acc: 59.252% test acc: 58.921% train exerAcc: 52.423% test exerAcc: 48.485%\n",
      "135\t train loss: 0.1599 train acc: 59.236% test acc: 58.979% train exerAcc: 52.863% test exerAcc: 50.000%\n",
      "140\t train loss: 0.1610 train acc: 59.300% test acc: 58.979% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "145\t train loss: 0.1622 train acc: 59.252% test acc: 59.094% train exerAcc: 52.423% test exerAcc: 48.485%\n",
      "150\t train loss: 0.1630 train acc: 59.252% test acc: 58.864% train exerAcc: 52.423% test exerAcc: 50.000%\n",
      "155\t train loss: 0.1596 train acc: 59.156% test acc: 58.979% train exerAcc: 52.423% test exerAcc: 51.515%\n",
      "160\t train loss: 0.1618 train acc: 59.236% test acc: 59.036% train exerAcc: 51.542% test exerAcc: 50.000%\n",
      "165\t train loss: 0.1601 train acc: 59.140% test acc: 58.979% train exerAcc: 52.423% test exerAcc: 51.515%\n",
      "170\t train loss: 0.1589 train acc: 59.188% test acc: 59.151% train exerAcc: 51.542% test exerAcc: 53.030%\n",
      "175\t train loss: 0.1594 train acc: 59.220% test acc: 59.208% train exerAcc: 51.982% test exerAcc: 56.061%\n",
      "180\t train loss: 0.1421 train acc: 59.268% test acc: 59.036% train exerAcc: 53.744% test exerAcc: 53.030%\n",
      "185\t train loss: 0.1397 train acc: 59.252% test acc: 58.979% train exerAcc: 53.304% test exerAcc: 51.515%\n",
      "190\t train loss: 0.1387 train acc: 59.188% test acc: 59.094% train exerAcc: 52.423% test exerAcc: 53.030%\n",
      "195\t train loss: 0.1367 train acc: 59.172% test acc: 59.151% train exerAcc: 52.423% test exerAcc: 51.515%\n",
      "200\t train loss: 0.1367 train acc: 59.252% test acc: 59.036% train exerAcc: 53.304% test exerAcc: 51.515%\n",
      "205\t train loss: 0.1355 train acc: 59.316% test acc: 59.266% train exerAcc: 52.423% test exerAcc: 53.030%\n",
      "210\t train loss: 0.1345 train acc: 59.172% test acc: 59.208% train exerAcc: 52.423% test exerAcc: 51.515%\n",
      "215\t train loss: 0.1341 train acc: 59.316% test acc: 59.208% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "220\t train loss: 0.1328 train acc: 59.300% test acc: 59.323% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "225\t train loss: 0.1327 train acc: 59.316% test acc: 59.323% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "230\t train loss: 0.1330 train acc: 59.380% test acc: 59.094% train exerAcc: 53.304% test exerAcc: 51.515%\n",
      "235\t train loss: 0.1326 train acc: 59.268% test acc: 59.380% train exerAcc: 53.304% test exerAcc: 53.030%\n",
      "240\t train loss: 0.1319 train acc: 59.204% test acc: 59.380% train exerAcc: 52.423% test exerAcc: 51.515%\n",
      "245\t train loss: 0.1318 train acc: 59.348% test acc: 59.667% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "250\t train loss: 0.1313 train acc: 59.284% test acc: 59.725% train exerAcc: 53.304% test exerAcc: 53.030%\n",
      "255\t train loss: 0.1317 train acc: 59.220% test acc: 59.495% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "260\t train loss: 0.1307 train acc: 59.156% test acc: 59.323% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "265\t train loss: 0.1308 train acc: 59.364% test acc: 59.323% train exerAcc: 53.304% test exerAcc: 51.515%\n",
      "270\t train loss: 0.1310 train acc: 59.412% test acc: 59.380% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "275\t train loss: 0.1306 train acc: 59.476% test acc: 59.725% train exerAcc: 52.423% test exerAcc: 51.515%\n",
      "280\t train loss: 0.1310 train acc: 59.332% test acc: 59.610% train exerAcc: 53.304% test exerAcc: 51.515%\n",
      "285\t train loss: 0.1302 train acc: 59.412% test acc: 59.495% train exerAcc: 53.304% test exerAcc: 51.515%\n",
      "290\t train loss: 0.1303 train acc: 59.348% test acc: 59.552% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "295\t train loss: 0.1306 train acc: 59.140% test acc: 59.438% train exerAcc: 51.542% test exerAcc: 51.515%\n",
      "300\t train loss: 0.1300 train acc: 59.220% test acc: 59.725% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "305\t train loss: 0.1312 train acc: 59.300% test acc: 59.725% train exerAcc: 53.304% test exerAcc: 53.030%\n",
      "310\t train loss: 0.1304 train acc: 59.284% test acc: 59.839% train exerAcc: 53.744% test exerAcc: 53.030%\n",
      "315\t train loss: 0.1300 train acc: 59.220% test acc: 59.552% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "320\t train loss: 0.1309 train acc: 59.316% test acc: 59.839% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "325\t train loss: 0.1302 train acc: 59.252% test acc: 59.610% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "330\t train loss: 0.1302 train acc: 59.220% test acc: 59.610% train exerAcc: 51.101% test exerAcc: 53.030%\n",
      "335\t train loss: 0.1302 train acc: 59.428% test acc: 59.380% train exerAcc: 53.304% test exerAcc: 54.545%\n",
      "340\t train loss: 0.1301 train acc: 59.364% test acc: 59.495% train exerAcc: 52.423% test exerAcc: 51.515%\n",
      "345\t train loss: 0.1301 train acc: 59.300% test acc: 59.438% train exerAcc: 53.304% test exerAcc: 51.515%\n",
      "350\t train loss: 0.1297 train acc: 59.364% test acc: 59.380% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "355\t train loss: 0.1299 train acc: 59.220% test acc: 59.552% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "360\t train loss: 0.1291 train acc: 59.108% test acc: 59.667% train exerAcc: 51.542% test exerAcc: 53.030%\n",
      "365\t train loss: 0.1299 train acc: 59.156% test acc: 59.610% train exerAcc: 53.304% test exerAcc: 53.030%\n",
      "370\t train loss: 0.1299 train acc: 59.428% test acc: 59.610% train exerAcc: 52.863% test exerAcc: 53.030%\n",
      "375\t train loss: 0.1299 train acc: 59.412% test acc: 59.839% train exerAcc: 52.423% test exerAcc: 53.030%\n",
      "380\t train loss: 0.1304 train acc: 59.332% test acc: 59.552% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "385\t train loss: 0.1298 train acc: 59.364% test acc: 59.495% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "390\t train loss: 0.1293 train acc: 59.364% test acc: 59.610% train exerAcc: 53.744% test exerAcc: 53.030%\n",
      "395\t train loss: 0.1296 train acc: 59.236% test acc: 59.610% train exerAcc: 53.744% test exerAcc: 53.030%\n",
      "399\t train loss: 0.1299 train acc: 59.268% test acc: 59.323% train exerAcc: 52.863% test exerAcc: 51.515%\n",
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.2002 train acc: 29.361% test acc: 30.345% train exerAcc: 34.855% test exerAcc: 34.615%\n",
      "5\t train loss: 0.1863 train acc: 42.741% test acc: 42.231% train exerAcc: 45.228% test exerAcc: 51.923%\n",
      "10\t train loss: 0.1764 train acc: 57.691% test acc: 53.453% train exerAcc: 48.548% test exerAcc: 50.000%\n",
      "15\t train loss: 0.1680 train acc: 58.229% test acc: 53.984% train exerAcc: 48.963% test exerAcc: 50.000%\n",
      "20\t train loss: 0.1639 train acc: 58.322% test acc: 54.449% train exerAcc: 48.963% test exerAcc: 50.000%\n",
      "25\t train loss: 0.1607 train acc: 58.614% test acc: 55.378% train exerAcc: 48.963% test exerAcc: 50.000%\n",
      "30\t train loss: 0.1746 train acc: 58.645% test acc: 55.113% train exerAcc: 51.037% test exerAcc: 50.000%\n",
      "35\t train loss: 0.1737 train acc: 58.707% test acc: 55.710% train exerAcc: 51.037% test exerAcc: 50.000%\n",
      "40\t train loss: 0.1724 train acc: 58.907% test acc: 55.578% train exerAcc: 51.037% test exerAcc: 50.000%\n",
      "45\t train loss: 0.1698 train acc: 58.999% test acc: 55.511% train exerAcc: 50.207% test exerAcc: 48.077%\n",
      "50\t train loss: 0.1696 train acc: 59.015% test acc: 55.777% train exerAcc: 49.793% test exerAcc: 48.077%\n",
      "55\t train loss: 0.1688 train acc: 59.045% test acc: 55.710% train exerAcc: 49.793% test exerAcc: 50.000%\n",
      "60\t train loss: 0.1687 train acc: 59.246% test acc: 55.976% train exerAcc: 50.622% test exerAcc: 50.000%\n",
      "65\t train loss: 0.1681 train acc: 59.323% test acc: 56.042% train exerAcc: 50.622% test exerAcc: 48.077%\n",
      "70\t train loss: 0.1673 train acc: 59.538% test acc: 55.710% train exerAcc: 50.622% test exerAcc: 48.077%\n",
      "75\t train loss: 0.1664 train acc: 59.677% test acc: 55.777% train exerAcc: 50.622% test exerAcc: 51.923%\n",
      "80\t train loss: 0.1671 train acc: 59.769% test acc: 55.843% train exerAcc: 51.037% test exerAcc: 50.000%\n",
      "85\t train loss: 0.1660 train acc: 59.692% test acc: 55.644% train exerAcc: 49.793% test exerAcc: 50.000%\n",
      "90\t train loss: 0.1662 train acc: 59.754% test acc: 55.710% train exerAcc: 51.452% test exerAcc: 50.000%\n",
      "95\t train loss: 0.1665 train acc: 59.646% test acc: 55.445% train exerAcc: 50.622% test exerAcc: 50.000%\n",
      "100\t train loss: 0.1702 train acc: 59.784% test acc: 55.644% train exerAcc: 51.037% test exerAcc: 48.077%\n",
      "105\t train loss: 0.1672 train acc: 59.800% test acc: 55.777% train exerAcc: 50.207% test exerAcc: 50.000%\n",
      "110\t train loss: 0.1633 train acc: 59.800% test acc: 55.843% train exerAcc: 51.452% test exerAcc: 51.923%\n",
      "115\t train loss: 0.1656 train acc: 59.800% test acc: 56.042% train exerAcc: 51.867% test exerAcc: 50.000%\n",
      "120\t train loss: 0.1639 train acc: 59.954% test acc: 56.042% train exerAcc: 53.942% test exerAcc: 55.769%\n",
      "125\t train loss: 0.1646 train acc: 59.969% test acc: 55.976% train exerAcc: 53.112% test exerAcc: 53.846%\n",
      "130\t train loss: 0.1610 train acc: 59.985% test acc: 56.109% train exerAcc: 53.942% test exerAcc: 53.846%\n",
      "135\t train loss: 0.1596 train acc: 60.031% test acc: 56.109% train exerAcc: 53.112% test exerAcc: 53.846%\n",
      "140\t train loss: 0.1615 train acc: 59.969% test acc: 56.175% train exerAcc: 53.112% test exerAcc: 53.846%\n",
      "145\t train loss: 0.1579 train acc: 59.938% test acc: 56.109% train exerAcc: 53.527% test exerAcc: 53.846%\n",
      "150\t train loss: 0.1586 train acc: 60.015% test acc: 55.976% train exerAcc: 54.772% test exerAcc: 53.846%\n",
      "155\t train loss: 0.1566 train acc: 59.969% test acc: 55.910% train exerAcc: 55.187% test exerAcc: 51.923%\n",
      "160\t train loss: 0.1609 train acc: 59.985% test acc: 55.976% train exerAcc: 54.772% test exerAcc: 51.923%\n",
      "165\t train loss: 0.1598 train acc: 60.000% test acc: 56.109% train exerAcc: 55.187% test exerAcc: 51.923%\n",
      "170\t train loss: 0.1603 train acc: 59.969% test acc: 55.843% train exerAcc: 53.942% test exerAcc: 51.923%\n",
      "175\t train loss: 0.1586 train acc: 59.908% test acc: 55.976% train exerAcc: 55.187% test exerAcc: 51.923%\n",
      "180\t train loss: 0.1413 train acc: 59.938% test acc: 55.843% train exerAcc: 55.187% test exerAcc: 51.923%\n",
      "185\t train loss: 0.1395 train acc: 60.031% test acc: 56.109% train exerAcc: 55.187% test exerAcc: 51.923%\n",
      "190\t train loss: 0.1378 train acc: 60.000% test acc: 56.042% train exerAcc: 54.772% test exerAcc: 50.000%\n",
      "195\t train loss: 0.1358 train acc: 60.015% test acc: 55.976% train exerAcc: 56.017% test exerAcc: 50.000%\n",
      "200\t train loss: 0.1347 train acc: 60.108% test acc: 55.843% train exerAcc: 56.017% test exerAcc: 50.000%\n",
      "205\t train loss: 0.1330 train acc: 60.046% test acc: 55.777% train exerAcc: 56.017% test exerAcc: 50.000%\n",
      "210\t train loss: 0.1335 train acc: 59.954% test acc: 55.710% train exerAcc: 56.017% test exerAcc: 48.077%\n",
      "215\t train loss: 0.1314 train acc: 60.139% test acc: 56.375% train exerAcc: 55.602% test exerAcc: 51.923%\n",
      "220\t train loss: 0.1309 train acc: 60.015% test acc: 56.042% train exerAcc: 56.017% test exerAcc: 50.000%\n",
      "225\t train loss: 0.1301 train acc: 60.000% test acc: 55.910% train exerAcc: 56.432% test exerAcc: 48.077%\n",
      "230\t train loss: 0.1303 train acc: 60.108% test acc: 56.175% train exerAcc: 55.602% test exerAcc: 48.077%\n",
      "235\t train loss: 0.1294 train acc: 60.046% test acc: 56.175% train exerAcc: 56.432% test exerAcc: 48.077%\n",
      "240\t train loss: 0.1293 train acc: 60.154% test acc: 56.375% train exerAcc: 56.432% test exerAcc: 46.154%\n",
      "245\t train loss: 0.1294 train acc: 60.108% test acc: 56.042% train exerAcc: 56.846% test exerAcc: 48.077%\n",
      "250\t train loss: 0.1291 train acc: 60.169% test acc: 56.375% train exerAcc: 56.432% test exerAcc: 50.000%\n",
      "255\t train loss: 0.1285 train acc: 60.154% test acc: 56.109% train exerAcc: 56.846% test exerAcc: 46.154%\n",
      "260\t train loss: 0.1287 train acc: 60.200% test acc: 56.109% train exerAcc: 56.432% test exerAcc: 48.077%\n",
      "265\t train loss: 0.1280 train acc: 60.216% test acc: 56.441% train exerAcc: 55.187% test exerAcc: 46.154%\n",
      "270\t train loss: 0.1284 train acc: 60.308% test acc: 56.441% train exerAcc: 55.602% test exerAcc: 48.077%\n",
      "275\t train loss: 0.1278 train acc: 60.123% test acc: 56.375% train exerAcc: 56.017% test exerAcc: 46.154%\n",
      "280\t train loss: 0.1285 train acc: 60.308% test acc: 56.441% train exerAcc: 56.432% test exerAcc: 48.077%\n",
      "285\t train loss: 0.1282 train acc: 60.185% test acc: 56.242% train exerAcc: 56.017% test exerAcc: 46.154%\n",
      "290\t train loss: 0.1279 train acc: 60.246% test acc: 56.441% train exerAcc: 56.432% test exerAcc: 48.077%\n",
      "295\t train loss: 0.1279 train acc: 60.385% test acc: 56.042% train exerAcc: 56.432% test exerAcc: 48.077%\n",
      "300\t train loss: 0.1278 train acc: 60.277% test acc: 56.242% train exerAcc: 56.017% test exerAcc: 48.077%\n",
      "305\t train loss: 0.1279 train acc: 60.216% test acc: 56.242% train exerAcc: 55.187% test exerAcc: 50.000%\n",
      "310\t train loss: 0.1273 train acc: 60.323% test acc: 55.976% train exerAcc: 56.017% test exerAcc: 48.077%\n",
      "315\t train loss: 0.1272 train acc: 60.293% test acc: 56.109% train exerAcc: 55.602% test exerAcc: 46.154%\n",
      "320\t train loss: 0.1274 train acc: 60.400% test acc: 56.242% train exerAcc: 56.846% test exerAcc: 48.077%\n",
      "325\t train loss: 0.1270 train acc: 60.216% test acc: 56.175% train exerAcc: 55.187% test exerAcc: 50.000%\n",
      "330\t train loss: 0.1268 train acc: 60.231% test acc: 56.175% train exerAcc: 55.602% test exerAcc: 50.000%\n",
      "335\t train loss: 0.1274 train acc: 60.231% test acc: 56.109% train exerAcc: 55.602% test exerAcc: 48.077%\n",
      "340\t train loss: 0.1260 train acc: 60.200% test acc: 56.042% train exerAcc: 56.017% test exerAcc: 48.077%\n",
      "345\t train loss: 0.1268 train acc: 60.231% test acc: 56.375% train exerAcc: 56.432% test exerAcc: 50.000%\n",
      "350\t train loss: 0.1268 train acc: 60.339% test acc: 56.175% train exerAcc: 56.432% test exerAcc: 48.077%\n",
      "355\t train loss: 0.1267 train acc: 60.246% test acc: 56.242% train exerAcc: 56.846% test exerAcc: 48.077%\n",
      "360\t train loss: 0.1270 train acc: 60.216% test acc: 56.308% train exerAcc: 54.772% test exerAcc: 50.000%\n",
      "365\t train loss: 0.1264 train acc: 60.169% test acc: 56.175% train exerAcc: 55.187% test exerAcc: 46.154%\n",
      "370\t train loss: 0.1267 train acc: 60.200% test acc: 55.976% train exerAcc: 54.772% test exerAcc: 48.077%\n",
      "375\t train loss: 0.1266 train acc: 60.246% test acc: 56.375% train exerAcc: 55.602% test exerAcc: 48.077%\n",
      "380\t train loss: 0.1267 train acc: 60.216% test acc: 56.308% train exerAcc: 55.187% test exerAcc: 50.000%\n",
      "385\t train loss: 0.1265 train acc: 60.246% test acc: 56.109% train exerAcc: 56.432% test exerAcc: 46.154%\n",
      "390\t train loss: 0.1267 train acc: 60.216% test acc: 56.109% train exerAcc: 56.017% test exerAcc: 48.077%\n",
      "395\t train loss: 0.1263 train acc: 60.185% test acc: 56.308% train exerAcc: 56.017% test exerAcc: 48.077%\n",
      "399\t train loss: 0.1256 train acc: 60.262% test acc: 56.042% train exerAcc: 54.772% test exerAcc: 46.154%\n"
     ]
    }
   ],
   "source": [
    "knowSched = [30, 180]\n",
    "physSched = [30, 100, 180]\n",
    "conSched = [100]\n",
    "\n",
    "for respond_perc in [.5]:\n",
    "# for respond_perc in [.75, .25]:\n",
    "    # for estate, include_state in [(True, True)]:\n",
    "    for splitQ, splitM in [(True, True)]:\n",
    "    # for splitQ, splitM in [(False, True)]:\n",
    "        for estate, include_state, fullq in [(True, True, True)]:\n",
    "            for numWeeks, insertpreds in [(1, True)]:\n",
    "                # for model, learning_rate, epochs in [(\"BasicNN\", .0054, 300), (\"LogisticRegressor\", .003, 400), (\"AdaptableLSTM\", .07, 200)]:\n",
    "                # for model, learning_rate, epochs in [(\"AdaptableLSTM\", .07, 200)]:\n",
    "                for model, learning_rate, epochs in [(\"BasicNN\", .0054, 300), (\"LogisticRegressor\", .003, 400)]:\n",
    "                    for smooth, noise in [(0, .07)]:\n",
    "                        for loss_fn in [\"MSELoss\"]:\n",
    "                            test_metrics, train_metrics, adjusted_losses = [], [], []\n",
    "                            for seed in range(3):\n",
    "                                np.random.seed(seed)\n",
    "                                torch.manual_seed(seed)\n",
    "                                e = Experiment(\n",
    "                                    modelSplit = splitM,\n",
    "                                    numValFolds = 5,\n",
    "                                    epochsToUpdateLabelMods = 10,\n",
    "                                    knowSchedule = knowSched,\n",
    "                                    consumpSchedule = conSched,\n",
    "                                    physSchedule = physSched,\n",
    "                                    data_kw={\"minw\": 2,\n",
    "                                            \"maxw\": 31,\n",
    "                                            \"include_state\": include_state,\n",
    "                                            \"include_pid\": False,\n",
    "                                            \"expanded_states\": estate,\n",
    "                                            \"top_respond_perc\": respond_perc,\n",
    "                                             \"full_questionnaire\": fullq,\n",
    "                                             \"num_weeks_history\": numWeeks,\n",
    "                                             \"insert_predictions\": insertpreds,\n",
    "                                             \"split_model_features\": splitM,\n",
    "                                             \"split_weekly_questions\": splitQ\n",
    "                                            },\n",
    "                                    model=model,\n",
    "                                    model_kw={\n",
    "                                        \"lossfn\": loss_fn,\n",
    "                                        # \"lossfn\": \"NDCG\",\n",
    "                                        # \"lossfn\": \"CrossEntropyLoss\",\n",
    "                                        \"hidden_size\": 25, \n",
    "                                        \"lr_step_mult\": .9, \n",
    "                                        \"lr_step_epochs\": 60,\n",
    "                                        \"opt_kw\": {\n",
    "                                            \"lr\": learning_rate\n",
    "                                        },\n",
    "                                        \"labelSmoothPerc\": smooth,\n",
    "                                        \"gaussianNoiseStd\": noise,\n",
    "                                        \"splitModel\": splitM,\n",
    "                                        \"splitWeeklyQuestions\": splitQ\n",
    "                                    },\n",
    "                                    train_kw={\n",
    "                                        \"epochs\": epochs,\n",
    "                                        \"n_subj\": 500,\n",
    "                                        \"rec_every\": 5,\n",
    "                                    })\n",
    "                                # torch.autograd.set_detect_anomaly(True)\n",
    "                                report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "                                individual_test_scores, labels = e.report_scores_individual_test()\n",
    "                                individual_train_scores, labels = e.report_scores_individual_train()\n",
    "\n",
    "\n",
    "\n",
    "                                dire = \"./experiment_output/\"\n",
    "                                # dire = \"./TEMP/\"\n",
    "                                fileprefix = f\"{model}LR{learning_rate}Resp{respond_perc}States{int(include_state)}Expanded{int(estate)}Seq{int(fulls)}Pred{int(insertpreds)}Smooth{smooth}Noise{noise}Split{int(splitQ)}{int(splitM)}\"\n",
    "                                np.savetxt(f\"{dire}TRAINMETRICS-{fileprefix}S{seed}.csv\", report[\"train_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}TESTMETRICS-{fileprefix}S{seed}.csv\", report[\"test_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}IDVDTESTMETRICS-{fileprefix}S{seed}.csv\", individual_test_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}IDVDTRAINMETRICS-{fileprefix}S{seed}.csv\", individual_train_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}TRAINLOSSES-{fileprefix}S{seed}.csv\", report[\"loss\"], delimiter = ',')\n",
    "\n",
    "                                preds1, preds2, preds3 = e.get_class_predictions(False)\n",
    "\n",
    "\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds1)\n",
    "                                plt.title(\"Train Predictions for Class 1\")\n",
    "                                plt.savefig(f\"{dire}/img/C1PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds2)\n",
    "                                plt.title(\"Train Predictions for Class 2\")\n",
    "                                plt.savefig(f\"{dire}/img/C2PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds3)\n",
    "                                plt.title(\"Train Predictions for Class 3\")\n",
    "                                plt.savefig(f\"{dire}/img/C3PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                preds1, preds2, preds3 = e.get_class_predictions(True)\n",
    "\n",
    "                                np.savetxt(f\"{dire}TESTPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TESTPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TESTPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds1)\n",
    "                                plt.title(\"Test Predictions for Class 1\")\n",
    "                                plt.savefig(f\"{dire}/img/C1PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds2)\n",
    "                                plt.title(\"Test Predictions for Class 2\")\n",
    "                                plt.savefig(f\"{dire}/img/C2PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds3)\n",
    "                                plt.title(\"Test Predictions for Class 3\")\n",
    "                                plt.savefig(f\"{dire}/img/C3PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.scatter(individual_test_scores[:, -1], individual_test_scores[:, labels.index(\"Acc\")])\n",
    "                                plt.title(\"Test Accuracy vs Response Count\")\n",
    "                                plt.savefig(f\"{dire}/img/TestACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "                                splot = plt.scatter(individual_train_scores[:, -1], individual_train_scores[:, labels.index(\"Acc\")])\n",
    "                                plt.title(\"Train Accuracy vs Response Count\")\n",
    "                                plt.savefig(f\"{dire}/img/TrainACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "                                plt.title(\"Train/Test Performance Over Training\")\n",
    "                                plt.legend()\n",
    "                                plt.ylabel(\"Metric\")\n",
    "                                plt.xlabel(\"Training Epoch\")\n",
    "                                plt.savefig(f\"{dire}/img/AccuracyVsEpoch-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "\n",
    "\n",
    "                                writer = open(f\"{dire}ALOSS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss[0]) for loss in report[\"loss\"]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "                                \n",
    "                                bestResult = np.argmax(report[\"test_metrics\"][:, labels.index(\"Acc\")])\n",
    "\n",
    "                                writer = open(f\"{dire}FINALTRAINMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss) for loss in report[\"train_metrics\"][bestResult, :]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "\n",
    "                                writer = open(f\"{dire}FINALTESTMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss) for loss in report[\"test_metrics\"][bestResult, :]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "\n",
    "                                Plotter.training_loss(report, dire)\n",
    "\n",
    "                                plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea7b5b-a82c-4039-b292-11c96933e9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
