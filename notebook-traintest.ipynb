{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t train loss: 0.1840 train acc: 51.343% test acc: 52.149%\n",
      "5\t train loss: 0.1837 train acc: 50.275% test acc: 50.738%\n",
      "10\t train loss: 0.1777 train acc: 51.343% test acc: 52.149%\n",
      "15\t train loss: 0.1752 train acc: 52.364% test acc: 52.534%\n",
      "20\t train loss: 0.1709 train acc: 53.150% test acc: 53.175%\n",
      "25\t train loss: 0.1686 train acc: 53.857% test acc: 54.073%\n",
      "30\t train loss: 0.1673 train acc: 53.920% test acc: 54.458%\n",
      "35\t train loss: 0.1662 train acc: 54.690% test acc: 54.971%\n",
      "40\t train loss: 0.1655 train acc: 55.035% test acc: 55.933%\n",
      "45\t train loss: 0.1644 train acc: 55.837% test acc: 55.997%\n",
      "50\t train loss: 0.1635 train acc: 55.884% test acc: 55.997%\n",
      "55\t train loss: 0.1629 train acc: 56.512% test acc: 56.318%\n",
      "60\t train loss: 0.1621 train acc: 56.874% test acc: 56.895%\n",
      "65\t train loss: 0.1613 train acc: 56.842% test acc: 56.446%\n",
      "70\t train loss: 0.1607 train acc: 56.984% test acc: 55.869%\n",
      "75\t train loss: 0.1599 train acc: 57.408% test acc: 55.292%\n",
      "80\t train loss: 0.1594 train acc: 57.738% test acc: 55.228%\n",
      "85\t train loss: 0.1589 train acc: 57.879% test acc: 55.484%\n",
      "90\t train loss: 0.1578 train acc: 57.926% test acc: 55.613%\n",
      "95\t train loss: 0.1574 train acc: 58.052% test acc: 55.997%\n",
      "100\t train loss: 0.1558 train acc: 58.209% test acc: 54.779%\n",
      "105\t train loss: 0.1559 train acc: 58.130% test acc: 54.907%\n",
      "110\t train loss: 0.1536 train acc: 58.429% test acc: 54.971%\n",
      "115\t train loss: 0.1533 train acc: 58.602% test acc: 55.613%\n",
      "120\t train loss: 0.1530 train acc: 58.570% test acc: 55.548%\n",
      "125\t train loss: 0.1519 train acc: 58.869% test acc: 55.356%\n",
      "130\t train loss: 0.1513 train acc: 59.309% test acc: 55.035%\n",
      "135\t train loss: 0.1514 train acc: 59.293% test acc: 55.099%\n",
      "140\t train loss: 0.1511 train acc: 59.686% test acc: 55.292%\n",
      "145\t train loss: 0.1515 train acc: 59.670% test acc: 55.356%\n",
      "149\t train loss: 0.1508 train acc: 60.000% test acc: 56.382%\n",
      "0\t train loss: 0.1885 train acc: 51.598% test acc: 51.149%\n",
      "5\t train loss: 0.1831 train acc: 51.598% test acc: 51.149%\n",
      "10\t train loss: 0.1772 train acc: 51.598% test acc: 51.149%\n",
      "15\t train loss: 0.1749 train acc: 51.598% test acc: 51.149%\n",
      "20\t train loss: 0.1741 train acc: 53.204% test acc: 52.799%\n",
      "25\t train loss: 0.1702 train acc: 53.943% test acc: 52.976%\n",
      "30\t train loss: 0.1658 train acc: 54.103% test acc: 53.270%\n",
      "35\t train loss: 0.1637 train acc: 54.167% test acc: 53.212%\n",
      "40\t train loss: 0.1599 train acc: 54.601% test acc: 54.095%\n",
      "45\t train loss: 0.1587 train acc: 55.195% test acc: 55.274%\n",
      "50\t train loss: 0.1575 train acc: 55.388% test acc: 55.274%\n",
      "55\t train loss: 0.1552 train acc: 56.030% test acc: 55.392%\n",
      "60\t train loss: 0.1535 train acc: 56.769% test acc: 56.040%\n",
      "65\t train loss: 0.1522 train acc: 57.411% test acc: 55.863%\n",
      "70\t train loss: 0.1507 train acc: 57.556% test acc: 56.040%\n",
      "75\t train loss: 0.1498 train acc: 58.134% test acc: 55.451%\n",
      "80\t train loss: 0.1489 train acc: 58.150% test acc: 55.745%\n",
      "85\t train loss: 0.1478 train acc: 58.359% test acc: 55.392%\n",
      "90\t train loss: 0.1468 train acc: 59.306% test acc: 55.392%\n",
      "95\t train loss: 0.1462 train acc: 59.916% test acc: 54.449%\n",
      "100\t train loss: 0.1453 train acc: 60.157% test acc: 54.862%\n",
      "105\t train loss: 0.1441 train acc: 60.173% test acc: 54.685%\n",
      "110\t train loss: 0.1441 train acc: 60.511% test acc: 54.744%\n",
      "115\t train loss: 0.1438 train acc: 60.944% test acc: 54.803%\n",
      "120\t train loss: 0.1421 train acc: 61.522% test acc: 54.744%\n",
      "125\t train loss: 0.1415 train acc: 61.924% test acc: 54.331%\n",
      "130\t train loss: 0.1423 train acc: 62.422% test acc: 54.449%\n",
      "135\t train loss: 0.1409 train acc: 61.892% test acc: 54.920%\n",
      "140\t train loss: 0.1399 train acc: 62.004% test acc: 54.626%\n",
      "145\t train loss: 0.1393 train acc: 62.871% test acc: 54.390%\n",
      "149\t train loss: 0.1393 train acc: 63.209% test acc: 54.154%\n",
      "0\t train loss: 0.1845 train acc: 51.832% test acc: 50.188%\n",
      "5\t train loss: 0.1771 train acc: 52.669% test acc: 51.068%\n",
      "10\t train loss: 0.1706 train acc: 52.811% test acc: 51.068%\n",
      "15\t train loss: 0.1652 train acc: 54.880% test acc: 52.701%\n",
      "20\t train loss: 0.1604 train acc: 56.270% test acc: 53.078%\n",
      "25\t train loss: 0.1567 train acc: 57.217% test acc: 54.899%\n",
      "30\t train loss: 0.1536 train acc: 57.817% test acc: 55.339%\n",
      "35\t train loss: 0.1510 train acc: 58.891% test acc: 55.905%\n",
      "40\t train loss: 0.1485 train acc: 59.744% test acc: 55.779%\n",
      "45\t train loss: 0.1463 train acc: 60.802% test acc: 55.402%\n",
      "50\t train loss: 0.1447 train acc: 61.766% test acc: 55.151%\n",
      "55\t train loss: 0.1434 train acc: 62.350% test acc: 55.276%\n",
      "60\t train loss: 0.1413 train acc: 63.092% test acc: 55.339%\n",
      "65\t train loss: 0.1400 train acc: 63.771% test acc: 55.967%\n",
      "70\t train loss: 0.1380 train acc: 64.387% test acc: 55.151%\n",
      "75\t train loss: 0.1372 train acc: 64.245% test acc: 55.590%\n",
      "80\t train loss: 0.1354 train acc: 65.082% test acc: 55.779%\n",
      "85\t train loss: 0.1341 train acc: 65.114% test acc: 55.528%\n",
      "90\t train loss: 0.1327 train acc: 65.998% test acc: 55.214%\n",
      "95\t train loss: 0.1326 train acc: 66.267% test acc: 55.465%\n",
      "100\t train loss: 0.1311 train acc: 66.693% test acc: 55.402%\n",
      "105\t train loss: 0.1302 train acc: 67.293% test acc: 54.837%\n",
      "110\t train loss: 0.1288 train acc: 67.625% test acc: 54.962%\n",
      "115\t train loss: 0.1281 train acc: 68.004% test acc: 55.590%\n",
      "120\t train loss: 0.1283 train acc: 68.588% test acc: 53.769%\n",
      "125\t train loss: 0.1267 train acc: 68.746% test acc: 54.083%\n",
      "130\t train loss: 0.1261 train acc: 68.936% test acc: 52.827%\n",
      "135\t train loss: 0.1252 train acc: 69.015% test acc: 53.266%\n",
      "140\t train loss: 0.1250 train acc: 68.335% test acc: 52.889%\n",
      "145\t train loss: 0.1269 train acc: 69.125% test acc: 53.392%\n",
      "149\t train loss: 0.1246 train acc: 68.825% test acc: 52.450%\n"
     ]
    }
   ],
   "source": [
    "for respond_perc in [.5]:\n",
    "# for respond_perc in [.75, .25]:\n",
    "    # for estate, include_state in [(True, True)]:\n",
    "    for estate, include_state, fullq in [(True, True, True)]:\n",
    "        for fulls, insertpreds in [(False, True)]:\n",
    "            for model, learning_rate, epochs in [(\"AdaptableLSTM\", .1, 150),]:\n",
    "            # for model, learning_rate, epochs in [(\"BasicNN\", .0054, 500), (\"LogisticRegressor\", .003, 500)]:\n",
    "                for smooth, noise in [(0, .07)]:\n",
    "                    for loss_fn in [\"MSELoss\"]:\n",
    "                        test_metrics, train_metrics, adjusted_losses = [], [], []\n",
    "                        for seed in range(3):\n",
    "                            np.random.seed(seed)\n",
    "                            torch.manual_seed(seed)\n",
    "                            e = Experiment(\n",
    "                                numValFolds = 5,\n",
    "                                epochsToUpdateLabelMods = 10,\n",
    "                                data_kw={\"minw\": 2,\n",
    "                                        \"maxw\": 29,\n",
    "                                        \"include_state\": include_state,\n",
    "                                        \"include_pid\": False,\n",
    "                                        \"expanded_states\": estate,\n",
    "                                        \"top_respond_perc\": respond_perc,\n",
    "                                         \"full_questionnaire\": fullq,\n",
    "                                         \"full_sequence\": fulls,\n",
    "                                         \"insert_predictions\": insertpreds\n",
    "                                        },\n",
    "                                model=model,\n",
    "                                model_kw={\n",
    "                                    \"lossfn\": loss_fn,\n",
    "                                    # \"lossfn\": \"NDCG\",\n",
    "                                    # \"lossfn\": \"CrossEntropyLoss\",\n",
    "                                    \"hidden_size\": 25, \n",
    "                                    \"lr_step_mult\": .9, \n",
    "                                    \"lr_step_epochs\": 60,\n",
    "                                    \"opt_kw\": {\n",
    "                                        \"lr\": learning_rate\n",
    "                                    },\n",
    "                                    \"labelSmoothPerc\": smooth,\n",
    "                                    \"gaussianNoiseStd\": noise\n",
    "                                },\n",
    "                                train_kw={\n",
    "                                    \"epochs\": epochs,\n",
    "                                    \"n_subj\": 500,\n",
    "                                    \"rec_every\": 5,\n",
    "                                })\n",
    "                            # torch.autograd.set_detect_anomaly(True)\n",
    "                            report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "                            individual_test_scores, labels = e.report_scores_individual_test()\n",
    "                            individual_train_scores, labels = e.report_scores_individual_train()\n",
    "\n",
    "\n",
    "\n",
    "                            dire = \"./experiment_output/\"\n",
    "                            fileprefix = f\"{model}LR{learning_rate}Resp{respond_perc}States{int(include_state)}Expanded{int(estate)}Seq{int(fulls)}Pred{int(insertpreds)}Smooth{smooth}Noise{noise}\"\n",
    "                            np.savetxt(f\"{dire}TRAINMETRICS-{fileprefix}S{seed}.csv\", report[\"train_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                            np.savetxt(f\"{dire}TESTMETRICS-{fileprefix}S{seed}.csv\", report[\"test_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                            np.savetxt(f\"{dire}IDVDTESTMETRICS-{fileprefix}S{seed}.csv\", individual_test_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                            np.savetxt(f\"{dire}IDVDTRAINMETRICS-{fileprefix}S{seed}.csv\", individual_train_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                            np.savetxt(f\"{dire}TRAINLOSSES-{fileprefix}S{seed}.csv\", report[\"loss\"], delimiter = ',')\n",
    "\n",
    "                            preds1, preds2, preds3 = e.get_class_predictions(False)\n",
    "\n",
    "\n",
    "                            np.savetxt(f\"{dire}TRAINPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                            np.savetxt(f\"{dire}TRAINPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                            np.savetxt(f\"{dire}TRAINPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                            plt.clf()\n",
    "                            splot = plt.hist(preds1)\n",
    "                            plt.title(\"Train Predictions for Class 1\")\n",
    "                            plt.savefig(f\"{dire}/img/C1PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                            plt.clf()\n",
    "                            splot = plt.hist(preds2)\n",
    "                            plt.title(\"Train Predictions for Class 2\")\n",
    "                            plt.savefig(f\"{dire}/img/C2PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                            plt.clf()\n",
    "                            splot = plt.hist(preds3)\n",
    "                            plt.title(\"Train Predictions for Class 3\")\n",
    "                            plt.savefig(f\"{dire}/img/C3PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                            preds1, preds2, preds3 = e.get_class_predictions(True)\n",
    "\n",
    "                            np.savetxt(f\"{dire}TESTPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                            np.savetxt(f\"{dire}TESTPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                            np.savetxt(f\"{dire}TESTPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                            plt.clf()\n",
    "                            splot = plt.hist(preds1)\n",
    "                            plt.title(\"Test Predictions for Class 1\")\n",
    "                            plt.savefig(f\"{dire}/img/C1PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                            plt.clf()\n",
    "                            splot = plt.hist(preds2)\n",
    "                            plt.title(\"Test Predictions for Class 2\")\n",
    "                            plt.savefig(f\"{dire}/img/C2PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                            plt.clf()\n",
    "                            splot = plt.hist(preds3)\n",
    "                            plt.title(\"Test Predictions for Class 3\")\n",
    "                            plt.savefig(f\"{dire}/img/C3PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "\n",
    "                            plt.clf()\n",
    "                            splot = plt.scatter(individual_test_scores[:, -1], individual_test_scores[:, labels.index(\"Acc\")])\n",
    "                            plt.title(\"Test Accuracy vs Response Count\")\n",
    "                            plt.savefig(f\"{dire}/img/TestACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                            plt.clf()\n",
    "                            splot = plt.scatter(individual_train_scores[:, -1], individual_train_scores[:, labels.index(\"Acc\")])\n",
    "                            plt.title(\"Train Accuracy vs Response Count\")\n",
    "                            plt.savefig(f\"{dire}/img/TrainACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                            plt.clf()\n",
    "                            \n",
    "                            splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "                            splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "                            splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "                            splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "                            plt.title(\"Train/Test Performance Over Training\")\n",
    "                            plt.legend()\n",
    "                            plt.ylabel(\"Metric\")\n",
    "                            plt.xlabel(\"Training Epoch\")\n",
    "                            plt.savefig(f\"{dire}/img/AccuracyVsEpoch-{fileprefix}S{seed}.png\")\n",
    "                            plt.clf()\n",
    "\n",
    "\n",
    "                            writer = open(f\"{dire}ALOSS-{fileprefix}.csv\", \"a\")\n",
    "                            writer.write(\",\".join([str(loss[0]) for loss in report[\"loss\"]]))\n",
    "                            writer.write(\"\\n\")\n",
    "                            writer.close()\n",
    "\n",
    "                            writer = open(f\"{dire}FINALTRAINMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                            writer.write(\",\".join([str(loss) for loss in report[\"train_metrics\"][-1, :]]))\n",
    "                            writer.write(\"\\n\")\n",
    "                            writer.close()\n",
    "\n",
    "                            writer = open(f\"{dire}FINALTESTMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                            writer.write(\",\".join([str(loss) for loss in report[\"test_metrics\"][-1, :]]))\n",
    "                            writer.write(\"\\n\")\n",
    "                            writer.close()\n",
    "\n",
    "                            Plotter.training_loss(report, dire)\n",
    "\n",
    "                            plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea7b5b-a82c-4039-b292-11c96933e9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
