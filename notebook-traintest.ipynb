{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268 537\n",
      "pmsg_sids\n",
      "paction_sids\n",
      "pmsg_ids\n",
      "qids\n",
      "response\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_47752\\665816988.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m                                         \u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                                         \u001b[1;34m\"n_subj\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                                         \u001b[1;34m\"rec_every\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m                                     })\n\u001b[0;32m     65\u001b[0m                                 \u001b[1;31m# torch.autograd.set_detect_anomaly(True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_kw, model, model_kw, train_kw, numValFolds, epochsToUpdateLabelMods, stateZeroEpochs, modelSplit, knowSchedule, physSchedule, consumpSchedule)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainConsumption\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBehaviorData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_weekly_questions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\utils\\behavior_data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, minw, maxw, include_pid, include_state, active_samp, window, train_perc, expanded_states, top_respond_perc, full_questionnaire, insert_predictions, num_weeks_history, one_hot_response_features, response_feature_noise, max_state_week, split_model_features, split_weekly_questions, category_specific_history)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatureList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\utils\\behavior_data.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m             \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatureList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\HealthLearning\\mdiabetes-behavior-modeling\\utils\\behavior_data.py\u001b[0m in \u001b[0;36mencode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_model_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"qcats\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m                 \u001b[0mbin_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_padded_binary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[0mfeatureList\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34mf\"q{idx+1}_cat\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_feat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "knowSched = [30, 180]\n",
    "physSched = [30, 100, 180]\n",
    "conSched = [100]\n",
    "respond_perc = .5\n",
    "splitQ, splitM = True, True\n",
    "\n",
    "for index1,(knowSched, physSched, conSched) in enumerate([([20], [50], [200])]):\n",
    "# for index1,(knowSched, physSched, conSched) in enumerate([([20], [50], [150]), ([20], [50], [120]), ([20], [40], [150]), ([10], [50], [150]), ([10], [40], [120])]):\n",
    "# for respond_perc in [.75, .25]:\n",
    "    # for estate, include_state in [(True, True)]:\n",
    "    for catHist in [False, True]:\n",
    "    # for splitQ, splitM in [(False, True)]:\n",
    "        for estate, include_state, fullq in [(True, True, True)]:\n",
    "            for numWeeks, insertpreds in [(1, True)]:\n",
    "                for model, learning_rate, epochs in [(\"BasicNN\", .0054, 200), (\"LogisticRegressor\", .003, 200), (\"AdaptableLSTM\", .07, 200)]:\n",
    "                # for model, learning_rate, epochs in [(\"AdaptableLSTM\", .07, 200)]:\n",
    "                # for model, learning_rate, epochs in [(\"BasicNN\", .0054, 300), (\"LogisticRegressor\", .003, 400)]:\n",
    "                    for smooth, noise in [(0, .07)]:\n",
    "                        for loss_fn in [\"MSELoss\"]:\n",
    "                            test_metrics, train_metrics, adjusted_losses = [], [], []\n",
    "                            for seed in range(3):\n",
    "                                np.random.seed(seed)\n",
    "                                torch.manual_seed(seed)\n",
    "                                e = Experiment(\n",
    "                                    modelSplit = splitM,\n",
    "                                    numValFolds = 5,\n",
    "                                    epochsToUpdateLabelMods = 10,\n",
    "                                    knowSchedule = knowSched,\n",
    "                                    consumpSchedule = conSched,\n",
    "                                    physSchedule = physSched,\n",
    "                                    data_kw={\"minw\": 2,\n",
    "                                            \"maxw\": 31,\n",
    "                                            \"include_state\": include_state,\n",
    "                                            \"include_pid\": False,\n",
    "                                            \"expanded_states\": estate,\n",
    "                                            \"top_respond_perc\": respond_perc,\n",
    "                                             \"full_questionnaire\": fullq,\n",
    "                                             \"num_weeks_history\": numWeeks,\n",
    "                                             \"insert_predictions\": insertpreds,\n",
    "                                             \"split_model_features\": splitM,\n",
    "                                             \"split_weekly_questions\": splitQ,\n",
    "                                             \"category_specific_history\": catHist\n",
    "                                            },\n",
    "                                    model=model,\n",
    "                                    model_kw={\n",
    "                                        \"lossfn\": loss_fn,\n",
    "                                        # \"lossfn\": \"NDCG\",\n",
    "                                        # \"lossfn\": \"CrossEntropyLoss\",\n",
    "                                        \"hidden_size\": 25, \n",
    "                                        \"lr_step_mult\": .9, \n",
    "                                        \"lr_step_epochs\": 60,\n",
    "                                        \"opt_kw\": {\n",
    "                                            \"lr\": learning_rate\n",
    "                                        },\n",
    "                                        \"labelSmoothPerc\": smooth,\n",
    "                                        \"gaussianNoiseStd\": noise,\n",
    "                                        \"splitModel\": splitM,\n",
    "                                        \"splitWeeklyQuestions\": splitQ\n",
    "                                    },\n",
    "                                    train_kw={\n",
    "                                        \"epochs\": epochs,\n",
    "                                        \"n_subj\": 500,\n",
    "                                        \"rec_every\": 5,\n",
    "                                    })\n",
    "                                # torch.autograd.set_detect_anomaly(True)\n",
    "                                report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "                                individual_test_scores, labels = e.report_scores_individual_test()\n",
    "                                individual_train_scores, labels = e.report_scores_individual_train()\n",
    "\n",
    "\n",
    "\n",
    "                                dire = \"./experiment_output/\"\n",
    "                                # dire = \"./TEMP/\"\n",
    "                                fileprefix = f\"{index1}{model}W{numWeeks}LR{learning_rate}Resp{respond_perc}States{int(include_state)}Expanded{int(estate)}Pred{int(insertpreds)}Smooth{smooth}Noise{noise}Split{int(splitQ)}{int(splitM)}\"\n",
    "                                np.savetxt(f\"{dire}TRAINMETRICS-{fileprefix}S{seed}.csv\", report[\"train_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}TESTMETRICS-{fileprefix}S{seed}.csv\", report[\"test_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}IDVDTESTMETRICS-{fileprefix}S{seed}.csv\", individual_test_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}IDVDTRAINMETRICS-{fileprefix}S{seed}.csv\", individual_train_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}TRAINLOSSES-{fileprefix}S{seed}.csv\", report[\"loss\"], delimiter = ',')\n",
    "\n",
    "                                preds1, preds2, preds3 = e.get_class_predictions(False)\n",
    "\n",
    "\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds1)\n",
    "                                plt.title(\"Train Predictions for Class 1\")\n",
    "                                plt.savefig(f\"{dire}/img/C1PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds2)\n",
    "                                plt.title(\"Train Predictions for Class 2\")\n",
    "                                plt.savefig(f\"{dire}/img/C2PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds3)\n",
    "                                plt.title(\"Train Predictions for Class 3\")\n",
    "                                plt.savefig(f\"{dire}/img/C3PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                preds1, preds2, preds3 = e.get_class_predictions(True)\n",
    "\n",
    "                                np.savetxt(f\"{dire}TESTPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TESTPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TESTPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds1)\n",
    "                                plt.title(\"Test Predictions for Class 1\")\n",
    "                                plt.savefig(f\"{dire}/img/C1PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds2)\n",
    "                                plt.title(\"Test Predictions for Class 2\")\n",
    "                                plt.savefig(f\"{dire}/img/C2PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds3)\n",
    "                                plt.title(\"Test Predictions for Class 3\")\n",
    "                                plt.savefig(f\"{dire}/img/C3PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.scatter(individual_test_scores[:, -1], individual_test_scores[:, labels.index(\"Acc\")])\n",
    "                                plt.title(\"Test Accuracy vs Response Count\")\n",
    "                                plt.savefig(f\"{dire}/img/TestACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "                                splot = plt.scatter(individual_train_scores[:, -1], individual_train_scores[:, labels.index(\"Acc\")])\n",
    "                                plt.title(\"Train Accuracy vs Response Count\")\n",
    "                                plt.savefig(f\"{dire}/img/TrainACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "                                plt.title(\"Train/Test Performance Over Training\")\n",
    "                                plt.legend()\n",
    "                                plt.ylabel(\"Metric\")\n",
    "                                plt.xlabel(\"Training Epoch\")\n",
    "                                plt.savefig(f\"{dire}/img/AccuracyVsEpoch-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "\n",
    "\n",
    "                                writer = open(f\"{dire}ALOSS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss[0]) for loss in report[\"loss\"]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "                                \n",
    "                                bestResult = np.argmax(report[\"test_metrics\"][:, labels.index(\"Acc\")])\n",
    "\n",
    "                                writer = open(f\"{dire}FINALTRAINMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss) for loss in report[\"train_metrics\"][bestResult, :]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "\n",
    "                                writer = open(f\"{dire}FINALTESTMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss) for loss in report[\"test_metrics\"][bestResult, :]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "\n",
    "                                Plotter.training_loss(report, dire)\n",
    "\n",
    "                                plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea7b5b-a82c-4039-b292-11c96933e9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
