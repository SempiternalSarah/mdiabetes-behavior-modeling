{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23791e19-fa29-4321-9a92-62c66249e206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "from utils.behavior_data import BehaviorData\n",
    "from visuals import Plotter\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.state_data import StateData\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ccab30-3fb9-4990-8492-e7d81a539a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.1893 train acc: 52.208% test acc: 54.029% train exerAcc: 48.261% test exerAcc: 52.381%\n",
      "5\t train loss: 0.1663 train acc: 53.340% test acc: 56.105% train exerAcc: 48.261% test exerAcc: 49.206%\n",
      "10\t train loss: 0.1606 train acc: 54.408% test acc: 57.021% train exerAcc: 47.391% test exerAcc: 52.381%\n",
      "15\t train loss: 0.1563 train acc: 57.159% test acc: 59.890% train exerAcc: 47.391% test exerAcc: 52.381%\n",
      "20\t train loss: 0.1542 train acc: 57.536% test acc: 59.585% train exerAcc: 49.130% test exerAcc: 50.794%\n",
      "25\t train loss: 0.1521 train acc: 57.756% test acc: 59.585% train exerAcc: 51.304% test exerAcc: 44.444%\n",
      "30\t train loss: 0.1699 train acc: 57.897% test acc: 60.256% train exerAcc: 53.043% test exerAcc: 49.206%\n",
      "35\t train loss: 0.1690 train acc: 57.882% test acc: 59.463% train exerAcc: 50.000% test exerAcc: 46.032%\n",
      "40\t train loss: 0.1689 train acc: 57.960% test acc: 59.158% train exerAcc: 51.304% test exerAcc: 47.619%\n",
      "45\t train loss: 0.1685 train acc: 58.102% test acc: 59.829% train exerAcc: 50.435% test exerAcc: 47.619%\n",
      "50\t train loss: 0.1681 train acc: 58.133% test acc: 59.951% train exerAcc: 49.130% test exerAcc: 49.206%\n",
      "55\t train loss: 0.1671 train acc: 57.976% test acc: 59.829% train exerAcc: 49.130% test exerAcc: 47.619%\n",
      "60\t train loss: 0.1674 train acc: 57.944% test acc: 60.134% train exerAcc: 48.696% test exerAcc: 47.619%\n",
      "65\t train loss: 0.1684 train acc: 57.850% test acc: 59.890% train exerAcc: 48.261% test exerAcc: 46.032%\n",
      "70\t train loss: 0.1684 train acc: 58.133% test acc: 59.829% train exerAcc: 47.826% test exerAcc: 46.032%\n",
      "75\t train loss: 0.1674 train acc: 58.117% test acc: 60.195% train exerAcc: 47.391% test exerAcc: 46.032%\n",
      "80\t train loss: 0.1686 train acc: 57.897% test acc: 59.890% train exerAcc: 48.261% test exerAcc: 46.032%\n",
      "85\t train loss: 0.1683 train acc: 58.054% test acc: 59.829% train exerAcc: 50.000% test exerAcc: 46.032%\n",
      "90\t train loss: 0.1682 train acc: 58.007% test acc: 59.829% train exerAcc: 47.391% test exerAcc: 46.032%\n",
      "95\t train loss: 0.1688 train acc: 58.070% test acc: 60.134% train exerAcc: 49.130% test exerAcc: 47.619%\n",
      "100\t train loss: 0.1703 train acc: 58.322% test acc: 60.012% train exerAcc: 51.304% test exerAcc: 47.619%\n",
      "105\t train loss: 0.1636 train acc: 58.542% test acc: 60.134% train exerAcc: 53.478% test exerAcc: 49.206%\n",
      "110\t train loss: 0.1639 train acc: 58.494% test acc: 60.012% train exerAcc: 53.043% test exerAcc: 47.619%\n",
      "115\t train loss: 0.1611 train acc: 58.620% test acc: 59.951% train exerAcc: 53.478% test exerAcc: 49.206%\n",
      "120\t train loss: 0.1616 train acc: 58.652% test acc: 60.317% train exerAcc: 56.087% test exerAcc: 53.968%\n",
      "125\t train loss: 0.1594 train acc: 58.699% test acc: 60.256% train exerAcc: 56.522% test exerAcc: 52.381%\n",
      "130\t train loss: 0.1584 train acc: 58.667% test acc: 60.379% train exerAcc: 53.913% test exerAcc: 53.968%\n",
      "135\t train loss: 0.1606 train acc: 58.652% test acc: 60.440% train exerAcc: 54.348% test exerAcc: 53.968%\n",
      "140\t train loss: 0.1572 train acc: 58.652% test acc: 60.379% train exerAcc: 53.913% test exerAcc: 52.381%\n",
      "145\t train loss: 0.1586 train acc: 58.683% test acc: 60.195% train exerAcc: 55.217% test exerAcc: 50.794%\n",
      "150\t train loss: 0.1560 train acc: 58.589% test acc: 60.501% train exerAcc: 53.913% test exerAcc: 50.794%\n",
      "155\t train loss: 0.1600 train acc: 58.746% test acc: 60.134% train exerAcc: 55.217% test exerAcc: 49.206%\n",
      "160\t train loss: 0.1579 train acc: 58.762% test acc: 60.256% train exerAcc: 56.522% test exerAcc: 53.968%\n",
      "165\t train loss: 0.1559 train acc: 58.636% test acc: 60.256% train exerAcc: 53.043% test exerAcc: 52.381%\n",
      "170\t train loss: 0.1518 train acc: 58.730% test acc: 60.379% train exerAcc: 56.087% test exerAcc: 53.968%\n",
      "175\t train loss: 0.1563 train acc: 58.746% test acc: 60.379% train exerAcc: 55.652% test exerAcc: 52.381%\n",
      "180\t train loss: 0.1352 train acc: 58.604% test acc: 60.256% train exerAcc: 53.478% test exerAcc: 52.381%\n",
      "185\t train loss: 0.1344 train acc: 58.573% test acc: 60.012% train exerAcc: 54.348% test exerAcc: 46.032%\n",
      "190\t train loss: 0.1344 train acc: 58.510% test acc: 60.012% train exerAcc: 52.174% test exerAcc: 47.619%\n",
      "195\t train loss: 0.1343 train acc: 58.620% test acc: 60.195% train exerAcc: 52.609% test exerAcc: 50.794%\n",
      "199\t train loss: 0.1344 train acc: 58.683% test acc: 60.012% train exerAcc: 54.783% test exerAcc: 49.206%\n",
      "['state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state' 'state'\n",
      " 'state' 'state' 'state' 'state' 'response_last_q1' 'response_last_q1'\n",
      " 'response_last_q1' 'paction_sids_q1' 'paction_sids_q1' 'paction_sids_q1'\n",
      " 'paction_sids_q1' 'paction_sids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1'\n",
      " 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'pmsg_ids_q1' 'qids_q1'\n",
      " 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'qids_q1' 'q1_cat' 'q1_cat']\n",
      "0\t train loss: 0.2029 train acc: 53.020% test acc: 52.897% train exerAcc: 48.458% test exerAcc: 48.485%\n",
      "5\t train loss: 0.1579 train acc: 58.213% test acc: 58.118% train exerAcc: 48.458% test exerAcc: 48.485%\n",
      "10\t train loss: 0.1505 train acc: 58.549% test acc: 57.487% train exerAcc: 48.458% test exerAcc: 48.485%\n",
      "15\t train loss: 0.1482 train acc: 58.853% test acc: 58.061% train exerAcc: 50.220% test exerAcc: 56.061%\n",
      "20\t train loss: 0.1469 train acc: 59.556% test acc: 59.151% train exerAcc: 52.423% test exerAcc: 56.061%\n",
      "25\t train loss: 0.1441 train acc: 60.099% test acc: 59.552% train exerAcc: 55.066% test exerAcc: 57.576%\n",
      "30\t train loss: 0.1621 train acc: 60.690% test acc: 59.266% train exerAcc: 58.590% test exerAcc: 56.061%\n",
      "35\t train loss: 0.1620 train acc: 60.339% test acc: 59.151% train exerAcc: 57.269% test exerAcc: 54.545%\n",
      "40\t train loss: 0.1617 train acc: 60.531% test acc: 59.094% train exerAcc: 55.947% test exerAcc: 57.576%\n",
      "45\t train loss: 0.1619 train acc: 60.275% test acc: 59.094% train exerAcc: 55.066% test exerAcc: 54.545%\n",
      "50\t train loss: 0.1622 train acc: 60.211% test acc: 58.864% train exerAcc: 53.744% test exerAcc: 51.515%\n",
      "55\t train loss: 0.1609 train acc: 60.291% test acc: 58.749% train exerAcc: 54.185% test exerAcc: 50.000%\n",
      "60\t train loss: 0.1620 train acc: 60.099% test acc: 58.692% train exerAcc: 53.744% test exerAcc: 48.485%\n",
      "65\t train loss: 0.1607 train acc: 60.179% test acc: 58.635% train exerAcc: 53.744% test exerAcc: 50.000%\n",
      "70\t train loss: 0.1616 train acc: 60.131% test acc: 58.405% train exerAcc: 53.304% test exerAcc: 50.000%\n",
      "75\t train loss: 0.1608 train acc: 60.067% test acc: 58.520% train exerAcc: 53.744% test exerAcc: 50.000%\n",
      "80\t train loss: 0.1622 train acc: 60.067% test acc: 58.577% train exerAcc: 53.304% test exerAcc: 50.000%\n",
      "85\t train loss: 0.1612 train acc: 60.147% test acc: 58.348% train exerAcc: 53.304% test exerAcc: 50.000%\n",
      "90\t train loss: 0.1618 train acc: 60.259% test acc: 58.290% train exerAcc: 53.304% test exerAcc: 50.000%\n",
      "95\t train loss: 0.1615 train acc: 60.067% test acc: 58.462% train exerAcc: 53.304% test exerAcc: 48.485%\n"
     ]
    }
   ],
   "source": [
    "knowSched = [30, 180]\n",
    "physSched = [30, 100, 180]\n",
    "conSched = [100]\n",
    "\n",
    "for respond_perc in [.5]:\n",
    "# for respond_perc in [.75, .25]:\n",
    "    # for estate, include_state in [(True, True)]:\n",
    "    for splitQ, splitM in [(True, True), (True, False), (False, True), (False, False)]:\n",
    "    # for splitQ, splitM in [(False, True)]:\n",
    "        for estate, include_state, fullq in [(True, True, True)]:\n",
    "            for fulls, insertpreds in [(False, True)]:\n",
    "                # for model, learning_rate, epochs in [(\"BasicNN\", .0054, 300), (\"LogisticRegressor\", .003, 400), (\"AdaptableLSTM\", .07, 200)]:\n",
    "                for model, learning_rate, epochs in [(\"AdaptableLSTM\", .07, 200)]:\n",
    "                # for model, learning_rate, epochs in [(\"BasicNN\", .0054, 300), (\"LogisticRegressor\", .003, 400)]:\n",
    "                    for smooth, noise in [(0, .07)]:\n",
    "                        for loss_fn in [\"MSELoss\"]:\n",
    "                            test_metrics, train_metrics, adjusted_losses = [], [], []\n",
    "                            for seed in range(3):\n",
    "                                np.random.seed(seed)\n",
    "                                torch.manual_seed(seed)\n",
    "                                e = Experiment(\n",
    "                                    modelSplit = splitM,\n",
    "                                    numValFolds = 5,\n",
    "                                    epochsToUpdateLabelMods = 10,\n",
    "                                    knowSchedule = knowSched,\n",
    "                                    consumpSchedule = conSched,\n",
    "                                    physSchedule = physSched,\n",
    "                                    data_kw={\"minw\": 2,\n",
    "                                            \"maxw\": 31,\n",
    "                                            \"include_state\": include_state,\n",
    "                                            \"include_pid\": False,\n",
    "                                            \"expanded_states\": estate,\n",
    "                                            \"top_respond_perc\": respond_perc,\n",
    "                                             \"full_questionnaire\": fullq,\n",
    "                                             \"full_sequence\": fulls,\n",
    "                                             \"insert_predictions\": insertpreds,\n",
    "                                             \"split_model_features\": splitM,\n",
    "                                             \"split_weekly_questions\": splitQ\n",
    "                                            },\n",
    "                                    model=model,\n",
    "                                    model_kw={\n",
    "                                        \"lossfn\": loss_fn,\n",
    "                                        # \"lossfn\": \"NDCG\",\n",
    "                                        # \"lossfn\": \"CrossEntropyLoss\",\n",
    "                                        \"hidden_size\": 25, \n",
    "                                        \"lr_step_mult\": .9, \n",
    "                                        \"lr_step_epochs\": 60,\n",
    "                                        \"opt_kw\": {\n",
    "                                            \"lr\": learning_rate\n",
    "                                        },\n",
    "                                        \"labelSmoothPerc\": smooth,\n",
    "                                        \"gaussianNoiseStd\": noise,\n",
    "                                        \"splitModel\": splitM,\n",
    "                                        \"splitWeeklyQuestions\": splitQ\n",
    "                                    },\n",
    "                                    train_kw={\n",
    "                                        \"epochs\": epochs,\n",
    "                                        \"n_subj\": 500,\n",
    "                                        \"rec_every\": 5,\n",
    "                                    })\n",
    "                                # torch.autograd.set_detect_anomaly(True)\n",
    "                                report = e.run()\n",
    "\n",
    "\n",
    "\n",
    "                                individual_test_scores, labels = e.report_scores_individual_test()\n",
    "                                individual_train_scores, labels = e.report_scores_individual_train()\n",
    "\n",
    "\n",
    "\n",
    "                                dire = \"./experiment_output/\"\n",
    "                                # dire = \"./TEMP/\"\n",
    "                                fileprefix = f\"{model}LR{learning_rate}Resp{respond_perc}States{int(include_state)}Expanded{int(estate)}Seq{int(fulls)}Pred{int(insertpreds)}Smooth{smooth}Noise{noise}Split{int(splitQ)}{int(splitM)}\"\n",
    "                                np.savetxt(f\"{dire}TRAINMETRICS-{fileprefix}S{seed}.csv\", report[\"train_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}TESTMETRICS-{fileprefix}S{seed}.csv\", report[\"test_metrics\"], delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}IDVDTESTMETRICS-{fileprefix}S{seed}.csv\", individual_test_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}IDVDTRAINMETRICS-{fileprefix}S{seed}.csv\", individual_train_scores, delimiter = ',', header = ','.join(report['metric_labels']))\n",
    "                                np.savetxt(f\"{dire}TRAINLOSSES-{fileprefix}S{seed}.csv\", report[\"loss\"], delimiter = ',')\n",
    "\n",
    "                                preds1, preds2, preds3 = e.get_class_predictions(False)\n",
    "\n",
    "\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TRAINPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds1)\n",
    "                                plt.title(\"Train Predictions for Class 1\")\n",
    "                                plt.savefig(f\"{dire}/img/C1PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds2)\n",
    "                                plt.title(\"Train Predictions for Class 2\")\n",
    "                                plt.savefig(f\"{dire}/img/C2PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds3)\n",
    "                                plt.title(\"Train Predictions for Class 3\")\n",
    "                                plt.savefig(f\"{dire}/img/C3PredsTrain-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                preds1, preds2, preds3 = e.get_class_predictions(True)\n",
    "\n",
    "                                np.savetxt(f\"{dire}TESTPREDS1-{fileprefix}S{seed}.csv\", preds1, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TESTPREDS2-{fileprefix}S{seed}.csv\", preds2, delimiter = ',')\n",
    "                                np.savetxt(f\"{dire}TESTPREDS3-{fileprefix}S{seed}.csv\", preds3, delimiter = ',')\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds1)\n",
    "                                plt.title(\"Test Predictions for Class 1\")\n",
    "                                plt.savefig(f\"{dire}/img/C1PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds2)\n",
    "                                plt.title(\"Test Predictions for Class 2\")\n",
    "                                plt.savefig(f\"{dire}/img/C2PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.hist(preds3)\n",
    "                                plt.title(\"Test Predictions for Class 3\")\n",
    "                                plt.savefig(f\"{dire}/img/C3PredsTest-{fileprefix}S{seed}.png\")\n",
    "\n",
    "\n",
    "                                plt.clf()\n",
    "                                splot = plt.scatter(individual_test_scores[:, -1], individual_test_scores[:, labels.index(\"Acc\")])\n",
    "                                plt.title(\"Test Accuracy vs Response Count\")\n",
    "                                plt.savefig(f\"{dire}/img/TestACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "                                splot = plt.scatter(individual_train_scores[:, -1], individual_train_scores[:, labels.index(\"Acc\")])\n",
    "                                plt.title(\"Train Accuracy vs Response Count\")\n",
    "                                plt.savefig(f\"{dire}/img/TrainACCvResponse-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"Acc\")], label=\"Train Acc.\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"Acc\")], label=\"Test Acc.\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"train_metrics\"][:, labels.index(\"MSE\")], label=\"Train MSE\")\n",
    "                                splot = plt.plot(report[\"rec_epochs\"], report[\"test_metrics\"][:, labels.index(\"MSE\")], label=\"Test MSE\")\n",
    "                                plt.title(\"Train/Test Performance Over Training\")\n",
    "                                plt.legend()\n",
    "                                plt.ylabel(\"Metric\")\n",
    "                                plt.xlabel(\"Training Epoch\")\n",
    "                                plt.savefig(f\"{dire}/img/AccuracyVsEpoch-{fileprefix}S{seed}.png\")\n",
    "                                plt.clf()\n",
    "\n",
    "\n",
    "                                writer = open(f\"{dire}ALOSS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss[0]) for loss in report[\"loss\"]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "                                \n",
    "                                bestResult = np.argmax(report[\"test_metrics\"][:, labels.index(\"Acc\")])\n",
    "\n",
    "                                writer = open(f\"{dire}FINALTRAINMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss) for loss in report[\"train_metrics\"][bestResult, :]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "\n",
    "                                writer = open(f\"{dire}FINALTESTMETRICS-{fileprefix}.csv\", \"a\")\n",
    "                                writer.write(\",\".join([str(loss) for loss in report[\"test_metrics\"][bestResult, :]]))\n",
    "                                writer.write(\"\\n\")\n",
    "                                writer.close()\n",
    "\n",
    "                                Plotter.training_loss(report, dire)\n",
    "\n",
    "                                plt.close(\"all\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cea7b5b-a82c-4039-b292-11c96933e9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6e339f590beffb2e62e02c6be9b431caf4c76db3ef9baeb9786d6033ee27a03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
